{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d91ff6b3",
      "metadata": {
        "id": "d91ff6b3"
      },
      "source": [
        "# Basic Data Types and Operators"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fdacdac",
      "metadata": {
        "id": "6fdacdac"
      },
      "source": [
        "### Comments, Variables, and `print()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6b01c4f",
      "metadata": {
        "id": "b6b01c4f",
        "outputId": "7982684d-8c4a-42d0-8af5-8b573f67d9b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3.5\n",
            "3 3.5\n",
            "3\n",
            "3.5\n"
          ]
        }
      ],
      "source": [
        "# This is a comment as it starts with #\n",
        "\n",
        "'''\n",
        "This is a\n",
        "multiple-line\n",
        "comment\n",
        "'''\n",
        "\n",
        "\"\"\"\n",
        "This is another\n",
        "multiple-line\n",
        "comment\n",
        "\"\"\"\n",
        "\n",
        "# Python is a strongly-typed language, so the type matters when performing operations.\n",
        "# On the other hand, Python is a dynamically-typed language, so the variable type\n",
        "# is determined based on the data it holds in the runtime\n",
        "\n",
        "# python has a function called \"print()\" that prints variables based on their types\n",
        "\n",
        "# Integer variable\n",
        "x = 3\n",
        "print(x)\n",
        "\n",
        "# Float variable\n",
        "y = 3.5\n",
        "print(y)\n",
        "\n",
        "# print() can print multiple objects, and it takes a parameter called \"sep\" that is by default a space\n",
        "print(x, y)\n",
        "\n",
        "# in the next line, we set the \"sep\" parameter as a new line \"\\n\"\n",
        "print(x, y, sep=\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3bea1ce",
      "metadata": {
        "id": "c3bea1ce"
      },
      "source": [
        "### Function `type()`\n",
        "you can use `type()` function to determine the type of the variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86034e9e",
      "metadata": {
        "id": "86034e9e",
        "outputId": "def484e7-464d-4935-feeb-a3c6080c8227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'int'> <class 'float'>\n"
          ]
        }
      ],
      "source": [
        "print(type(x), type(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e9236f",
      "metadata": {
        "id": "e7e9236f"
      },
      "source": [
        "### Strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f75b4cc",
      "metadata": {
        "id": "1f75b4cc",
        "outputId": "75e511a6-b00c-4e22-c106-7d1516b07bc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "String with double quotes\n",
            "String with single quotes\n",
            "String with 'single quotes' in it\n",
            "String with \"double quotes\" in it\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "# strings - both single or double quotes can be used to define strings\n",
        "z = \"String with double quotes\"\n",
        "w = 'String with single quotes'\n",
        "a = \"String with 'single quotes' in it\"\n",
        "b = 'String with \"double quotes\" in it'\n",
        "print(z, w, a, b, sep='\\n')\n",
        "print (type(z))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bc2e3a2",
      "metadata": {
        "id": "7bc2e3a2"
      },
      "source": [
        "### Casting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "770b8689",
      "metadata": {
        "id": "770b8689",
        "outputId": "ac308829-27d7-491a-e4fd-08cd593b9ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n",
            "3.0\n"
          ]
        }
      ],
      "source": [
        "x = str(3)\n",
        "y = int(\"3\")\n",
        "z = float(3)\n",
        "print(x, y, z, sep='\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bf515be",
      "metadata": {
        "id": "1bf515be"
      },
      "source": [
        "### Boolean Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b662f242",
      "metadata": {
        "id": "b662f242",
        "outputId": "24dee877-4580-4673-d99a-2d324d2eab64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True False 1 0\n",
            "<class 'bool'>\n"
          ]
        }
      ],
      "source": [
        "a = True\n",
        "b = False\n",
        "print(a, b, int(a), int(b))\n",
        "print(type(a))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc254559",
      "metadata": {
        "id": "fc254559"
      },
      "source": [
        "### Lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10e2ff82",
      "metadata": {
        "id": "10e2ff82",
        "outputId": "1658d4c8-d1e4-42d7-aa46-8f684465a558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the original list:                                [1, 'NLP', 2.3]\n",
            "This is the list after adding \"4\" to it:                  [1, 'NLP', 2.3, '4']\n",
            "This is the list after extending it with [5, 6]:          [1, 'NLP', 2.3, '4', 5, 6]\n",
            "This is the list after inserting \"0\" at index \"2\":        [1, 'NLP', 0, 2.3, '4', 5, 6]\n",
            "This is the list after removing \"NLP\" from it:              [1, 0, 2.3, '4', 5, 6]\n",
            "The list after removing the item of index 3, which is 4: [1, 0, 2.3, 5, 6]\n",
            "This is the list after sorting it:                        [0, 1, 2.3, 5, 6]\n",
            "This is the list after reversing it:                      [6, 5, 2.3, 1, 0]\n",
            "number of items in the list:                              5\n",
            "first item in the list:                                   6\n",
            "last item in the list:                                    0\n",
            "from item of index \"1\" to item of index \"2\":              [5, 2.3]\n",
            "from the first item to item of index \"1\":                 [6, 5]\n",
            "from item of index \"1\" to the last item:                  [5, 2.3, 1, 0]\n",
            "the list after changing the second item from \"NLP\" to 2:  [6, 2, 2.3, 1, 0]\n",
            "the list after removing the first item:                   [2, 2.3, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "# a list can contain items of different types\n",
        "l = [1, \"NLP\", 2.3]\n",
        "print('This is the original list:                               ', l)\n",
        "\n",
        "# add item to list\n",
        "l.append(\"4\")\n",
        "print('This is the list after adding \"4\" to it:                 ', l)\n",
        "\n",
        "# extend list with another list\n",
        "l.extend([5, 6])\n",
        "print('This is the list after extending it with [5, 6]:         ', l)\n",
        "\n",
        "# insert item to list at a specific index\n",
        "l.insert(2, 0)\n",
        "print('This is the list after inserting \"0\" at index \"2\":       ', l)\n",
        "\n",
        "# remove item from list\n",
        "l.remove(\"NLP\")\n",
        "print('This is the list after removing \"NLP\" from it:             ', l)\n",
        "\n",
        "# remove item from list by index\n",
        "d=l.pop(3)\n",
        "print(f\"The list after removing the item of index 3, which is {d}: {l}\")\n",
        "\n",
        "# sort list\n",
        "l.sort()\n",
        "print('This is the list after sorting it:                       ', l)\n",
        "\n",
        "# reverse list\n",
        "l.reverse()\n",
        "print('This is the list after reversing it:                     ', l)\n",
        "\n",
        "\n",
        "# get count of items in a list\n",
        "print('number of items in the list:                             ', len(l))\n",
        "\n",
        "# access items in a list (zero-indexed)\n",
        "print('first item in the list:                                  ', l[0])\n",
        "\n",
        "# access the last item in a list\n",
        "print('last item in the list:                                   ', l[-1])\n",
        "\n",
        "# access a slice from the list\n",
        "print('from item of index \"1\" to item of index \"2\":             ', l[1:3])\n",
        "print('from the first item to item of index \"1\":                ', l[:2])\n",
        "print('from item of index \"1\" to the last item:                 ', l[1:])\n",
        "\n",
        "# set item in a list\n",
        "l[1] = 2\n",
        "\n",
        "print('the list after changing the second item from \"NLP\" to 2: ', l)\n",
        "\n",
        "# remove item from list\n",
        "del l[0]\n",
        "\n",
        "print('the list after removing the first item:                  ', l)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dc33a03",
      "metadata": {
        "id": "0dc33a03"
      },
      "source": [
        "### Dictionaries\n",
        "Dictionaries store data as (`key`, `value`) pairs of arbitrary types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acbfc8cf",
      "metadata": {
        "id": "acbfc8cf",
        "outputId": "31c41a89-7f65-4e4c-f584-26fc23af4734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "item with a string key:               1\n",
            "item with an int key:                 3\n",
            "item with a float key:                4.5\n",
            "value of key 4.5:                     4.5\n",
            "dictionary after adding an item:      {'1': 1, '2': 2, 3: '3', 4.5: '4.5', 5: '5'}\n",
            "dictionary after updating an item:    {'1': 1, '2': 2, 3: '3', 4.5: '4.5', 5: 'five'}\n",
            "keys in the dictionary:               dict_keys(['1', '2', 3, 4.5, 5])\n",
            "values in the dictionary:             dict_values([1, 2, '3', '4.5', 'five'])\n",
            "items in the dictionary:              dict_items([('1', 1), ('2', 2), (3, '3'), (4.5, '4.5'), (5, 'five')])\n",
            "dictionary after popping the item with key '1', which is 1: {'2': 2, 3: '3', 4.5: '4.5', 5: 'five'}\n",
            "dictionary after deleting an item:    {3: '3', 4.5: '4.5', 5: 'five'}\n"
          ]
        }
      ],
      "source": [
        "d = {\n",
        "        \"1\": 1,\n",
        "        \"2\": 2,\n",
        "        3: \"3\",\n",
        "        4.5:\"4.5\"\n",
        "    }\n",
        "print('item with a string key:              ', d[\"1\"])\n",
        "print('item with an int key:                ', d[3])\n",
        "print('item with a float key:               ', d[4.5])\n",
        "\n",
        "# get value of a specific key\n",
        "print('value of key 4.5:                    ', d.get(4.5))\n",
        "\n",
        "# add item to the dictionary\n",
        "d[5] = \"5\"\n",
        "print('dictionary after adding an item:     ', d)\n",
        "\n",
        "# update item in the dictionary\n",
        "d[5] = \"five\"\n",
        "print('dictionary after updating an item:   ', d)\n",
        "\n",
        "# print all keys in the dictionary\n",
        "print('keys in the dictionary:              ', d.keys())\n",
        "\n",
        "# print all values in the dictionary\n",
        "print('values in the dictionary:            ', d.values())\n",
        "\n",
        "# print all items in the dictionary\n",
        "print('items in the dictionary:             ', d.items())\n",
        "\n",
        "# pop item from the dictionary\n",
        "item=d.pop('1')\n",
        "print(f\"dictionary after popping the item with key '1', which is {item}: {d}\")\n",
        "\n",
        "\n",
        "# delete item with a specific key\n",
        "del d[\"2\"]\n",
        "print('dictionary after deleting an item:   ', d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88fb50cc",
      "metadata": {
        "id": "88fb50cc"
      },
      "source": [
        "### Tuples\n",
        "Tuples are `immutable` objects, lists are `mutable`.\n",
        "\n",
        "Tuples cannot be changed while lists can."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a9a5ed",
      "metadata": {
        "id": "e6a9a5ed",
        "outputId": "aca40a29-9000-4925-db7a-9bcd8569db2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original tuple:   (1, 2.5, '3')\n",
            "first item        1\n",
            "\n",
            "after adding 4:   (1, 2.5, '3', 4)\n",
            "tuple\n",
            "{(1, 2.5, '3', 4): 'tuple'}\n"
          ]
        }
      ],
      "source": [
        "t = (1, 2.5, \"3\")\n",
        "print('original tuple:  ', t)\n",
        "print('first item       ', t[0])\n",
        "print()\n",
        "\n",
        "\"\"\"\n",
        "Tuple is immutable, although you can use the + operator to concatenate several tuples.\n",
        " The old object is still present at this point, and a new object is created.\n",
        "\"\"\"\n",
        "t = t + (4,)\n",
        "print('after adding 4:  ', t)\n",
        "\n",
        "# tuples can be a key of a dict\n",
        "d = {t: \"tuple\"}\n",
        "print(d[t])\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0ee489d",
      "metadata": {
        "id": "f0ee489d",
        "outputId": "3d3a6161-1afb-49f5-ff42-67f32c2d3cd0"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'tuple' object does not support item assignment",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# this will get an error (recall: tuple are immutable)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# tuples are immutable so you can't change them\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
          ]
        }
      ],
      "source": [
        "# this will get an error (recall: tuple are immutable)\n",
        "# tuples are immutable so you can't change them\n",
        "t[0]=2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4569543a",
      "metadata": {
        "id": "4569543a"
      },
      "source": [
        "### Sets\n",
        "- `Unchangeable`: same as tuples\n",
        "- `unindexed`: we cannot access a specific index\n",
        "- `unique values only`: no duplicate values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef6b98f4",
      "metadata": {
        "id": "ef6b98f4",
        "outputId": "5573b871-434a-4f81-cd9e-29796cf61785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'c', 'a', 'b'}\n",
            "{'c', 5, 'b'}\n",
            "{'c', 5, 'b'}\n"
          ]
        }
      ],
      "source": [
        "s = {\"a\", \"b\", \"c\"}\n",
        "print(s)\n",
        "\n",
        "# add item to the set\n",
        "s.add(5)\n",
        "# remove item from the set\n",
        "s.remove(\"a\")\n",
        "print(s)\n",
        "\n",
        "# try adding duplicate items\n",
        "s = {5, \"b\", \"c\", \"b\"}\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d523783c",
      "metadata": {
        "id": "d523783c",
        "outputId": "f226b0f0-80cf-4144-a0d9-98bbf10f63b4"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'set' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# this will get an error (recall: sets not subscriptable)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'set' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "# this will get an error (recall: sets not subscriptable)\n",
        "s[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dbf140a",
      "metadata": {
        "id": "0dbf140a"
      },
      "source": [
        "### Conversions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb11f604",
      "metadata": {
        "id": "cb11f604",
        "outputId": "9ea923ca-b2fd-4f16-c4c7-33c12176f23f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'b', 'c', ' ', 'd', 'e', 'f']\n"
          ]
        }
      ],
      "source": [
        "# convert a string to a list of characters\n",
        "l=list(\"abc def\")\n",
        "\n",
        "print(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71923714",
      "metadata": {
        "id": "71923714",
        "outputId": "40a4bb37-9235-4bda-919d-e633b0bef175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'two', 'one'}\n"
          ]
        }
      ],
      "source": [
        "s= set([\"one\",\"two\",\"one\"])\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aa7e5d2",
      "metadata": {
        "id": "3aa7e5d2",
        "outputId": "b3b32acf-28f1-4c3d-fbdb-724afba3caa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['words', 'with', 'spaces']\n",
            "['1', '4', '8', '2']\n"
          ]
        }
      ],
      "source": [
        "w=\"words with spaces\".split() # split the string into a list of words\n",
        "print(w)\n",
        "\n",
        "# split the string on a specific character (,)\n",
        "n=\"1,4,8,2\".split(\",\")\n",
        "print(n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23dc4ba1",
      "metadata": {
        "id": "23dc4ba1",
        "outputId": "49c7f1b8-0d27-44a6-b053-55e9ee44bfa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "words with spaces\n",
            "1,4,8,2\n"
          ]
        }
      ],
      "source": [
        "# join the list of words into a string\n",
        "print(' '.join(w) )\n",
        "\n",
        "# join the list of words into a string with a comma between them\n",
        "print(','.join(n))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "735bc2e1",
      "metadata": {
        "id": "735bc2e1"
      },
      "source": [
        "### Arithmetic Operators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e66df76e",
      "metadata": {
        "id": "e66df76e",
        "outputId": "b9852653-abdb-41f1-b20e-959801b31924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "-1\n",
            "1.5\n",
            "1\n",
            "6\n",
            "1\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "x = 2\n",
        "y = 3\n",
        "print(x + y)\n",
        "print(x - y)\n",
        "print(y / x)\n",
        "print(y // x)\n",
        "print(x * y)\n",
        "print(y % x)\n",
        "print(x**y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2843f9f1",
      "metadata": {
        "id": "2843f9f1"
      },
      "source": [
        "### Assignment operators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f99ddc82",
      "metadata": {
        "id": "f99ddc82",
        "outputId": "f3d97ee2-423c-4736-e681-3bca906cec2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "3\n",
            "2\n",
            "1.0\n",
            "3.0\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "x = 2\n",
        "print(x)\n",
        "x += 1\n",
        "print(x)\n",
        "x -= 1\n",
        "print(x)\n",
        "x /= 2\n",
        "print(x)\n",
        "x *= 3\n",
        "print(x)\n",
        "x //= 2\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5974f71",
      "metadata": {
        "id": "c5974f71"
      },
      "source": [
        "### Comparison operators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad761d62",
      "metadata": {
        "id": "ad761d62",
        "outputId": "7aa9a5ce-43d1-4934-a28e-f99acaee1c91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "x = 3\n",
        "y = 2\n",
        "print(x == y)\n",
        "print(x != y)\n",
        "print(x >= y)\n",
        "print(x <= y)\n",
        "print(x > y)\n",
        "print(x < y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6901b21d",
      "metadata": {
        "id": "6901b21d"
      },
      "source": [
        "### Logical Operators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "655c3b8e",
      "metadata": {
        "id": "655c3b8e",
        "outputId": "9cb6a99f-ace0-48ac-c3be-148c27e1ad52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "x = True\n",
        "y = False\n",
        "print(x and y)\n",
        "print(x or y)\n",
        "print(not y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "977c721e",
      "metadata": {
        "id": "977c721e"
      },
      "source": [
        "# Flow Control\n",
        "`Blocks` in `Python` are structured using `indentation`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e8e01df",
      "metadata": {
        "id": "8e8e01df"
      },
      "source": [
        "### `if`-`elif`-`else`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b565f7f",
      "metadata": {
        "id": "7b565f7f",
        "outputId": "4067d63d-e9fb-4f30-dc8e-ce30d9a87b17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x < y\n"
          ]
        }
      ],
      "source": [
        "x = 2\n",
        "y = 3\n",
        "if x > y:\n",
        "    # here indentation is important\n",
        "    print (\"x > y\")\n",
        "elif x < y:\n",
        "    print(\"x < y\")\n",
        "else:\n",
        "    print(\"x = y\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8130c0b",
      "metadata": {
        "id": "a8130c0b"
      },
      "source": [
        "### `while` loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7ba08e7",
      "metadata": {
        "id": "f7ba08e7",
        "outputId": "88e6927c-f7e3-481d-a210-a090394c718e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "# while loops\n",
        "i = 0\n",
        "while i < 10:\n",
        "    print(i)\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c2a6afe",
      "metadata": {
        "id": "1c2a6afe"
      },
      "source": [
        "### `for` loops\n",
        "for is used to iterate over sequences like lists, dictionaries, sets, strings, tuples, ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c99c712",
      "metadata": {
        "id": "9c99c712",
        "outputId": "923a582a-0f4d-45c2-93a7-de83d5899dec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5.3\n",
            "\n",
            "[2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[2, 4, 6, 8]\n",
            "\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "\n",
            "N\n",
            "L\n",
            "P\n"
          ]
        }
      ],
      "source": [
        "l = [\"1\", \"2\", 3, 4, 5.3]\n",
        "for item in l:\n",
        "    print(item)\n",
        "\n",
        "print()\n",
        "\n",
        "# range function\n",
        "print(list(range(2, 10)))\n",
        "print(list(range(10)))\n",
        "print(list(range(2, 10, 2)))\n",
        "print()\n",
        "\n",
        "for i in range(2, 10):\n",
        "    print(i)\n",
        "\n",
        "print()\n",
        "\n",
        "s = \"NLP\"\n",
        "for c in s:\n",
        "    print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0b1c093",
      "metadata": {
        "id": "c0b1c093"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be7868ca",
      "metadata": {
        "id": "be7868ca"
      },
      "outputs": [],
      "source": [
        "# function with no arguments\n",
        "def func():\n",
        "    print(\"in func\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99620132",
      "metadata": {
        "id": "99620132",
        "outputId": "cb3c94d1-553a-4596-f65d-53be2a9f5c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in func\n"
          ]
        }
      ],
      "source": [
        "func()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2e643ae",
      "metadata": {
        "id": "b2e643ae"
      },
      "outputs": [],
      "source": [
        "# function with arguments\n",
        "def func(a):\n",
        "    print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e81f703a",
      "metadata": {
        "id": "e81f703a",
        "outputId": "fc348d19-3241-4963-be7c-a5d2c2f2e7ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "[1, 2]\n"
          ]
        }
      ],
      "source": [
        "func(3)\n",
        "func([1, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d958ba4",
      "metadata": {
        "id": "3d958ba4"
      },
      "outputs": [],
      "source": [
        "# function that makes some logic and returns a value\n",
        "def func(a):\n",
        "    return a + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf7be4bd",
      "metadata": {
        "id": "cf7be4bd",
        "outputId": "2154798f-b77f-4419-acb4-4dc2db847cb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "f = func(3)\n",
        "print(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72675e3e",
      "metadata": {
        "id": "72675e3e"
      },
      "outputs": [],
      "source": [
        "# function that takes a variable number of arguments\n",
        "def func(*args):\n",
        "    for arg in args:\n",
        "        print(arg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d953f4",
      "metadata": {
        "id": "31d953f4",
        "outputId": "78d13d29-8990-431c-e6cc-ed855a958412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "NLP\n"
          ]
        }
      ],
      "source": [
        "func(1, 2, \"NLP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f914bb7",
      "metadata": {
        "id": "0f914bb7"
      },
      "outputs": [],
      "source": [
        "# function with 3 arguments\n",
        "def func(a, b, c):\n",
        "    print(a, b, c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f21853a",
      "metadata": {
        "id": "0f21853a",
        "outputId": "c7ccd34e-6ac4-4c9d-da46-1ed4521e07b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 2 3\n",
            "1 2 3\n"
          ]
        }
      ],
      "source": [
        "func(1, 2, 3)\n",
        "func(b=2, a=1, c=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f0edb3e",
      "metadata": {
        "id": "0f0edb3e"
      },
      "outputs": [],
      "source": [
        "# a function with an argument that has a default value\n",
        "def func(a,b=1):\n",
        "    print(a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a142cd2",
      "metadata": {
        "id": "5a142cd2",
        "outputId": "33c55f37-6251-48a2-cdce-1be6c6f6cff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 5\n",
            "2 1\n"
          ]
        }
      ],
      "source": [
        "func(2,5)\n",
        "func(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c3cdf40",
      "metadata": {
        "id": "9c3cdf40",
        "outputId": "321c26e6-ad05-4aea-ea4c-21d4e7379d1d"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "parameter without a default follows parameter with a default (25820532.py, line 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[35], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def func(b=9,a):\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m parameter without a default follows parameter with a default\n"
          ]
        }
      ],
      "source": [
        "# get an error (non-default argument follows default argument)\n",
        "def func(b=9,a):\n",
        "    print(a,b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e20ac8b",
      "metadata": {
        "id": "2e20ac8b"
      },
      "outputs": [],
      "source": [
        "# a function with a keyword arguments\n",
        "def func(**kwargs):\n",
        "    print(kwargs[\"subject\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42aae6b4",
      "metadata": {
        "id": "42aae6b4",
        "outputId": "a9603201-9c27-47e7-dc12-7d0045ac4b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLP\n"
          ]
        }
      ],
      "source": [
        "func(subject=\"NLP\", section=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb02733b",
      "metadata": {
        "id": "cb02733b"
      },
      "source": [
        "# Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7adc17dd",
      "metadata": {
        "id": "7adc17dd"
      },
      "outputs": [],
      "source": [
        "class Human:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        print(\"Human created\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"My name is {self.name}\"\n",
        "\n",
        "    def changeName(self, name):\n",
        "        print(f\"replacing {self.name} with {name}\")\n",
        "        self.name = name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f0f220",
      "metadata": {
        "id": "84f0f220",
        "outputId": "3f72b4e2-ab0e-41ea-ebb4-4cf0232b17f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human created\n",
            "My name is omar\n",
            "replacing omar with mohamed\n",
            "My name is mohamed\n"
          ]
        }
      ],
      "source": [
        "h = Human(\"omar\")\n",
        "print(h)\n",
        "h.changeName(\"mohamed\")\n",
        "print(h)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3e78432",
      "metadata": {
        "id": "c3e78432"
      },
      "outputs": [],
      "source": [
        "class Student(Human):\n",
        "    def __init__(self, name, year):\n",
        "        Human.__init__(self, name)\n",
        "        self.year = year\n",
        "        print(\"Student created\")\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Student name: {self.name}\\nIn year: {self.year}\"\n",
        "\n",
        "    def passed(self):\n",
        "        self.year += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd53b979",
      "metadata": {
        "id": "fd53b979",
        "outputId": "ba0c3143-be07-4923-8bd1-2cd054d8d05b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Human created\n",
            "Student created\n",
            "Student name: omar\n",
            "In year: 4\n",
            "Student name: omar\n",
            "In year: 5\n"
          ]
        }
      ],
      "source": [
        "s = Student(\"omar\", 4)\n",
        "print(s)\n",
        "s.passed()\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Qs4pD_a4uLEp",
      "metadata": {
        "id": "Qs4pD_a4uLEp"
      },
      "source": [
        "# Numpy\n",
        "Numpy is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G0XDw55BuQYW",
      "metadata": {
        "id": "G0XDw55BuQYW"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6slpTMrPufTx",
      "metadata": {
        "id": "6slpTMrPufTx"
      },
      "source": [
        "## Arrays\n",
        "\n",
        "A numpy array is a grid of values, all of the same type, and is indexed by a tuple of nonnegative integers. The number of dimensions is the rank of the array; the shape of an array is a tuple of integers giving the size of the array along each dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c5138c6",
      "metadata": {
        "id": "8c5138c6"
      },
      "source": [
        "We can initialize numpy arrays from nested Python lists, and access elements using square brackets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WtPBS3bQuXg7",
      "metadata": {
        "id": "WtPBS3bQuXg7",
        "outputId": "3848a7d8-d38b-40ef-cf15-56dd1c9219bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> (3,) 1 2 3\n",
            "[5 2 3]\n"
          ]
        }
      ],
      "source": [
        "a = np.array([1, 2, 3])  # Create a rank 1 array\n",
        "print(type(a), a.shape, a[0], a[1], a[2])\n",
        "a[0] = 5                 # Change an element of the array\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XK4dfTURuqGZ",
      "metadata": {
        "id": "XK4dfTURuqGZ",
        "outputId": "bbf59349-43fb-42b1-92fa-6db9e5f740dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ],
      "source": [
        "b = np.array([[1,2,3],[4,5,6]])   # Create a rank 2 array\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ILaGS94yusoG",
      "metadata": {
        "id": "ILaGS94yusoG",
        "outputId": "9d48e355-3ba6-4614-acb6-fd4064c9ac13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 3)\n",
            "1 2 4\n"
          ]
        }
      ],
      "source": [
        "print(b.shape)\n",
        "print(b[0, 0], b[0, 1], b[1, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wxHzlbbuuu0B",
      "metadata": {
        "id": "wxHzlbbuuu0B"
      },
      "source": [
        "Numpy also provides many functions to create arrays:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VWMwqIdouvRR",
      "metadata": {
        "id": "VWMwqIdouvRR",
        "outputId": "aa8601bd-4853-42d8-dbf3-3a35911c540a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0.]\n",
            " [0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "a = np.zeros((2,2))  # Create an array of all zeros\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZVD2iEfBuw3q",
      "metadata": {
        "id": "ZVD2iEfBuw3q",
        "outputId": "5dbb797b-bcea-4db0-9bee-a614bad21203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 1.]]\n"
          ]
        }
      ],
      "source": [
        "b = np.ones((1,2))   # Create an array of all ones\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VfQ8qdpKux8R",
      "metadata": {
        "id": "VfQ8qdpKux8R",
        "outputId": "c322abb9-9eed-4fd2-e37a-41bcd571bd33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[7 7]\n",
            " [7 7]]\n"
          ]
        }
      ],
      "source": [
        "c = np.full((2,2), 7) # Create a constant array\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gadqbHfHuzOe",
      "metadata": {
        "id": "gadqbHfHuzOe",
        "outputId": "6e693ff3-5c67-4861-f1a4-a93fcf0173af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "d = np.eye(2)        # Create a 2x2 identity matrix\n",
        "print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G11BZwlmu0aM",
      "metadata": {
        "id": "G11BZwlmu0aM",
        "outputId": "e472e72c-5ec6-4809-e44c-5bfeb1b7ab41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.33703282 0.18304777]\n",
            " [0.99886052 0.44683842]]\n"
          ]
        }
      ],
      "source": [
        "e = np.random.random((2,2)) # Create an array filled with random values\n",
        "print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_tqceYPEu3Rx",
      "metadata": {
        "id": "_tqceYPEu3Rx"
      },
      "source": [
        "## Array Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "II2Bo6Ibu982",
      "metadata": {
        "id": "II2Bo6Ibu982"
      },
      "source": [
        "Slicing: Similar to Python lists, numpy arrays can be sliced. Since arrays may be multidimensional, you must specify a slice for each dimension of the array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LS5UHHJ4u5AJ",
      "metadata": {
        "id": "LS5UHHJ4u5AJ",
        "outputId": "db1b2bc6-029b-4f46-a480-8e5fa32822a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2 3]\n",
            " [6 7]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create the following rank 2 array with shape (3, 4)\n",
        "# [[ 1  2  3  4]\n",
        "#  [ 5  6  7  8]\n",
        "#  [ 9 10 11 12]]\n",
        "a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
        "\n",
        "# Use slicing to pull out the subarray consisting of the first 2 rows\n",
        "# and columns 1 and 2; b is the following array of shape (2, 2):\n",
        "# [[2 3]\n",
        "#  [6 7]]\n",
        "b = a[:2, 1:3]\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zidGcOhIvDMu",
      "metadata": {
        "id": "zidGcOhIvDMu"
      },
      "source": [
        "A slice of an array is a view into the same data, so modifying it will modify the original array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cMdycOOvDkh",
      "metadata": {
        "id": "1cMdycOOvDkh",
        "outputId": "a9ef218d-35d7-45b3-d443-d477d0b606d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "77\n"
          ]
        }
      ],
      "source": [
        "print(a[0, 1])\n",
        "b[0, 0] = 77    # b[0, 0] is the same piece of data as a[0, 1]\n",
        "print(a[0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bMuH0liWvLRt",
      "metadata": {
        "id": "bMuH0liWvLRt",
        "outputId": "c3c0384f-3e52-4b62-f325-abd7bf25817a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]]\n",
            "[5 6 7 8] (4,)\n",
            "[[5 6 7 8]] (1, 4)\n",
            "[[5 6 7 8]] (1, 4)\n"
          ]
        }
      ],
      "source": [
        "# Create the following rank 2 array with shape (3, 4)\n",
        "a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
        "print(a)\n",
        "\n",
        "row_r1 = a[1, :]    # Rank 1 view of the second row of a\n",
        "row_r2 = a[1:2, :]  # Rank 2 view of the second row of a\n",
        "row_r3 = a[[1], :]  # Rank 2 view of the second row of a\n",
        "print(row_r1, row_r1.shape)\n",
        "print(row_r2, row_r2.shape)\n",
        "print(row_r3, row_r3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FQqRiPEovUNa",
      "metadata": {
        "id": "FQqRiPEovUNa",
        "outputId": "87b7a249-359f-45bc-ac4e-9b29fc3c2b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2  6 10] (3,)\n",
            "\n",
            "[[ 2]\n",
            " [ 6]\n",
            " [10]] (3, 1)\n"
          ]
        }
      ],
      "source": [
        "# We can make the same distinction when accessing columns of an array:\n",
        "col_r1 = a[:, 1]\n",
        "col_r2 = a[:, 1:2]\n",
        "print(col_r1, col_r1.shape)\n",
        "print()\n",
        "print(col_r2, col_r2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LCuy1mvWwTAt",
      "metadata": {
        "id": "LCuy1mvWwTAt",
        "outputId": "fcbc3061-723d-4b70-bcc5-17daab2658a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 4 5]\n",
            "[1 4 5]\n"
          ]
        }
      ],
      "source": [
        "a = np.array([[1,2], [3, 4], [5, 6]])\n",
        "\n",
        "# An example of integer array indexing.\n",
        "# The returned array will have shape (3,) and\n",
        "print(a[[0, 1, 2], [0, 1, 0]])\n",
        "\n",
        "# The above example of integer array indexing is equivalent to this:\n",
        "print(np.array([a[0, 0], a[1, 1], a[2, 0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SQc5QuXDwUis",
      "metadata": {
        "id": "SQc5QuXDwUis",
        "outputId": "c9e817f2-8400-450e-daa7-ebfa282797f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2 2]\n",
            "[2 2]\n"
          ]
        }
      ],
      "source": [
        "# When using integer array indexing, you can reuse the same\n",
        "# element from the source array:\n",
        "print(a[[0, 0], [1, 1]])\n",
        "\n",
        "# Equivalent to the previous integer array indexing example\n",
        "print(np.array([a[0, 1], a[0, 1]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "v5-x-O81wi6m",
      "metadata": {
        "id": "v5-x-O81wi6m"
      },
      "source": [
        "Boolean array indexing: Boolean array indexing lets you pick out arbitrary elements of an array. Frequently this type of indexing is used to select the elements of an array that satisfy some condition. Here is an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A_v4qREYwjTY",
      "metadata": {
        "id": "A_v4qREYwjTY",
        "outputId": "a6614802-f824-47a1-ad38-396198d61cbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[False False]\n",
            " [ True  True]\n",
            " [ True  True]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([[1,2], [3, 4], [5, 6]])\n",
        "\n",
        "bool_idx = (a > 2)  # Find the elements of a that are bigger than 2;\n",
        "                    # this returns a numpy array of Booleans of the same\n",
        "                    # shape as a, where each slot of bool_idx tells\n",
        "                    # whether that element of a is > 2.\n",
        "\n",
        "print(bool_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KIU-FF1-wl5T",
      "metadata": {
        "id": "KIU-FF1-wl5T",
        "outputId": "7a9ba7ce-a206-477a-a063-8e4f11b807ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3 4 5 6]\n",
            "[3 4 5 6]\n"
          ]
        }
      ],
      "source": [
        "# We use boolean array indexing to construct a rank 1 array\n",
        "# consisting of the elements of a corresponding to the True values\n",
        "# of bool_idx\n",
        "print(a[bool_idx])\n",
        "\n",
        "# We can do all of the above in a single concise statement:\n",
        "print(a[a > 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FtqJ_U1Nwsp6",
      "metadata": {
        "id": "FtqJ_U1Nwsp6"
      },
      "source": [
        "## Datatypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bh-YkTjlwuIC",
      "metadata": {
        "id": "Bh-YkTjlwuIC",
        "outputId": "904d2dd5-e986-4a9e-b105-2d1288dd9799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "int64 float64 int64\n"
          ]
        }
      ],
      "source": [
        "x = np.array([1, 2])  # Let numpy choose the datatype\n",
        "y = np.array([1.0, 2.0])  # Let numpy choose the datatype\n",
        "z = np.array([1, 2], dtype=np.int64)  # Force a particular datatype\n",
        "\n",
        "print(x.dtype, y.dtype, z.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CrM109fzwykb",
      "metadata": {
        "id": "CrM109fzwykb"
      },
      "source": [
        "## Array Math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KgRZcmTAw0cs",
      "metadata": {
        "id": "KgRZcmTAw0cs",
        "outputId": "70473028-86dc-4c00-de55-d97d19518996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 6.  8.]\n",
            " [10. 12.]]\n",
            "[[ 6.  8.]\n",
            " [10. 12.]]\n"
          ]
        }
      ],
      "source": [
        "x = np.array([[1,2],[3,4]], dtype=np.float64)\n",
        "y = np.array([[5,6],[7,8]], dtype=np.float64)\n",
        "\n",
        "# Elementwise sum; both produce the array\n",
        "print(x + y)\n",
        "print(np.add(x, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q0-9YXKPw8Va",
      "metadata": {
        "id": "Q0-9YXKPw8Va",
        "outputId": "d2fe3b00-7e27-4386-a3e9-220521a9f074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-4. -4.]\n",
            " [-4. -4.]]\n",
            "[[-4. -4.]\n",
            " [-4. -4.]]\n"
          ]
        }
      ],
      "source": [
        "# Elementwise difference; both produce the array\n",
        "print(x - y)\n",
        "print(np.subtract(x, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3JnkNr6ww-yi",
      "metadata": {
        "id": "3JnkNr6ww-yi",
        "outputId": "aee4f0c3-7658-40f9-bbbf-9d41ae930d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 5. 12.]\n",
            " [21. 32.]]\n",
            "[[ 5. 12.]\n",
            " [21. 32.]]\n"
          ]
        }
      ],
      "source": [
        "# Elementwise product; both produce the array\n",
        "print(x * y)\n",
        "print(np.multiply(x, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D59o2fzKw_u4",
      "metadata": {
        "id": "D59o2fzKw_u4",
        "outputId": "ab1519b6-e517-4568-fcbb-cc134ca3f7a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.2        0.33333333]\n",
            " [0.42857143 0.5       ]]\n",
            "[[0.2        0.33333333]\n",
            " [0.42857143 0.5       ]]\n"
          ]
        }
      ],
      "source": [
        "# Elementwise division; both produce the array\n",
        "# [[ 0.2         0.33333333]\n",
        "#  [ 0.42857143  0.5       ]]\n",
        "print(x / y)\n",
        "print(np.divide(x, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yTa9HiUDxBOe",
      "metadata": {
        "id": "yTa9HiUDxBOe",
        "outputId": "878444d6-0466-4982-fe97-8b00c2912c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.         1.41421356]\n",
            " [1.73205081 2.        ]]\n"
          ]
        }
      ],
      "source": [
        "# Elementwise square root; produces the array\n",
        "# [[ 1.          1.41421356]\n",
        "#  [ 1.73205081  2.        ]]\n",
        "print(np.sqrt(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FytWRCs8xFfC",
      "metadata": {
        "id": "FytWRCs8xFfC",
        "outputId": "f2189594-824a-44ea-b629-b3cb13a9754c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "219\n",
            "219\n"
          ]
        }
      ],
      "source": [
        "x = np.array([[1,2],[3,4]])\n",
        "y = np.array([[5,6],[7,8]])\n",
        "\n",
        "v = np.array([9,10])\n",
        "w = np.array([11, 12])\n",
        "\n",
        "# Inner product of vectors; both produce 219\n",
        "print(v.dot(w))\n",
        "print(np.dot(v, w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mv5NFqRBxH7O",
      "metadata": {
        "id": "mv5NFqRBxH7O",
        "outputId": "ac625757-b9a6-4bc3-c6b4-24f5293db668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "219\n"
          ]
        }
      ],
      "source": [
        "# Equavilant to np.dot\n",
        "print(v @ w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "piAa6aL-xLjD",
      "metadata": {
        "id": "piAa6aL-xLjD",
        "outputId": "87927fc3-b01a-429a-dd5d-d37722f1fbcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "[4 6]\n",
            "[3 7]\n"
          ]
        }
      ],
      "source": [
        "x = np.array([[1,2],[3,4]])\n",
        "\n",
        "print(np.sum(x))  # Compute sum of all elements; prints \"10\"\n",
        "print(np.sum(x, axis=0))  # Compute sum of each column; prints \"[4 6]\"\n",
        "print(np.sum(x, axis=1))  # Compute sum of each row; prints \"[3 7]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1RrC7laxXWT",
      "metadata": {
        "id": "d1RrC7laxXWT",
        "outputId": "1bb8f3b9-a472-48b5-a544-496a5a143d48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "transpose\n",
            " [[1 3]\n",
            " [2 4]]\n"
          ]
        }
      ],
      "source": [
        "print(x)\n",
        "print(\"transpose\\n\", x.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ElUcbT_WxezU",
      "metadata": {
        "id": "ElUcbT_WxezU",
        "outputId": "fe13fbd0-06e0-40f3-b515-2a505a772ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2 3]]\n",
            "transpose\n",
            " [[1]\n",
            " [2]\n",
            " [3]]\n"
          ]
        }
      ],
      "source": [
        "v = np.array([[1,2,3]])\n",
        "print(v)\n",
        "print(\"transpose\\n\", v.T)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Oaal73PMxgtL",
      "metadata": {
        "id": "Oaal73PMxgtL"
      },
      "source": [
        "## Broadcasting"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B6_mxuxOxm-X",
      "metadata": {
        "id": "B6_mxuxOxm-X"
      },
      "source": [
        "Broadcasting is a powerful mechanism that allows numpy to work with arrays of different shapes when performing arithmetic operations. Frequently we have a smaller array and a larger array, and we want to use the smaller array multiple times to perform some operation on the larger array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ERVDK-MxidV",
      "metadata": {
        "id": "5ERVDK-MxidV",
        "outputId": "54854402-ff17-4e5d-a5a5-f91c1287c690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 2  2  4]\n",
            " [ 5  5  7]\n",
            " [ 8  8 10]\n",
            " [11 11 13]]\n"
          ]
        }
      ],
      "source": [
        "# We will add the vector v to each row of the matrix x,\n",
        "# storing the result in the matrix y\n",
        "x = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
        "v = np.array([1, 0, 1])\n",
        "y = np.empty_like(x)   # Create an empty matrix with the same shape as x\n",
        "\n",
        "# Add the vector v to each row of the matrix x with an explicit loop\n",
        "for i in range(4):\n",
        "    y[i, :] = x[i, :] + v\n",
        "\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DhVnu27TxzLU",
      "metadata": {
        "id": "DhVnu27TxzLU"
      },
      "source": [
        "This works; however when the matrix x is very large, computing an explicit loop in Python could be slow. Note that adding the vector v to each row of the matrix x is equivalent to forming a matrix vv by stacking multiple copies of v vertically, then performing elementwise summation of x and vv. We could implement this approach like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3JTeBLSbxzsx",
      "metadata": {
        "id": "3JTeBLSbxzsx",
        "outputId": "56dc51b5-1336-4938-b6d7-080a6afb54fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 0 1]\n",
            " [1 0 1]\n",
            " [1 0 1]\n",
            " [1 0 1]]\n"
          ]
        }
      ],
      "source": [
        "vv = np.tile(v, (4, 1))  # Stack 4 copies of v on top of each other\n",
        "print(vv)                # Prints \"[[1 0 1]\n",
        "                         #          [1 0 1]\n",
        "                         #          [1 0 1]\n",
        "                         #          [1 0 1]]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "g0TnkhKpx5Wa",
      "metadata": {
        "id": "g0TnkhKpx5Wa",
        "outputId": "c01f6ab6-75e2-4c8f-f41c-4d9ac3e78a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 2  2  4]\n",
            " [ 5  5  7]\n",
            " [ 8  8 10]\n",
            " [11 11 13]]\n"
          ]
        }
      ],
      "source": [
        "y = x + vv  # Add x and vv elementwise\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_TxsyOg5x8GK",
      "metadata": {
        "id": "_TxsyOg5x8GK"
      },
      "source": [
        "Numpy broadcasting allows us to perform this computation without actually creating multiple copies of v. Consider this version, using broadcasting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SPNjtRimx8xt",
      "metadata": {
        "id": "SPNjtRimx8xt",
        "outputId": "a06cc19d-f95d-4988-a8c7-da0d34630572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 2  2  4]\n",
            " [ 5  5  7]\n",
            " [ 8  8 10]\n",
            " [11 11 13]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# We will add the vector v to each row of the matrix x,\n",
        "# storing the result in the matrix y\n",
        "x = np.array([[1,2,3], [4,5,6], [7,8,9], [10, 11, 12]])\n",
        "v = np.array([1, 0, 1])\n",
        "y = x + v  # Add v to each row of x using broadcasting\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d2a6132",
      "metadata": {
        "id": "7d2a6132"
      },
      "source": [
        "# Towards Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50a7c32f",
      "metadata": {
        "id": "50a7c32f"
      },
      "outputs": [],
      "source": [
        "# Natural Language Toolkit\n",
        "# !pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e3b0e7",
      "metadata": {
        "id": "06e3b0e7",
        "outputId": "baffe173-ec91-4d45-eeb6-67a8a57976a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package chat80 to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package swadesh to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('book')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99aac30c",
      "metadata": {
        "id": "99aac30c",
        "outputId": "8676f557-3613-4e6c-c960-2050fcb6463b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "from nltk.book import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "831ff216",
      "metadata": {
        "id": "831ff216",
        "outputId": "03011da0-c7ff-42de-8ad4-40a2f6f428ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nltk.text.Text"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d556fe28",
      "metadata": {
        "id": "d556fe28",
        "outputId": "16d26fe5-5f80-4dd8-d097-432942024f90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Text: Moby Dick by Herman Melville 1851>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b06dc8d3",
      "metadata": {
        "id": "b06dc8d3",
        "outputId": "da1f2348-17de-41af-9993-736b094d3492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Displaying 11 of 11 matches:\n",
            "ong the former , one was of a most monstrous size . ... This came towards us , \n",
            "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
            "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
            "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
            "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
            "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
            "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
            "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
            "ere to enter upon those still more monstrous stories of them which are to be fo\n",
            "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
            "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
          ]
        }
      ],
      "source": [
        "# search for a specific word in a text\n",
        "text1.concordance(\"monstrous\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaec2642",
      "metadata": {
        "id": "aaec2642",
        "outputId": "dfc76d46-3e5c-405f-df6a-081a880f82b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44764"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# the number of tokens in a given text (words and punctuation symbols)\n",
        "len(text3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2bbc533",
      "metadata": {
        "id": "c2bbc533",
        "outputId": "46d8b282-761f-4fe9-8e8b-2b406fe9223c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['!',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " ',)',\n",
              " '.',\n",
              " '.)',\n",
              " ':',\n",
              " ';',\n",
              " ';)',\n",
              " '?',\n",
              " '?)',\n",
              " 'A',\n",
              " 'Abel',\n",
              " 'Abelmizraim',\n",
              " 'Abidah',\n",
              " 'Abide',\n",
              " 'Abimael',\n",
              " 'Abimelech',\n",
              " 'Abr',\n",
              " 'Abrah',\n",
              " 'Abraham',\n",
              " 'Abram',\n",
              " 'Accad',\n",
              " 'Achbor',\n",
              " 'Adah',\n",
              " 'Adam',\n",
              " 'Adbeel',\n",
              " 'Admah',\n",
              " 'Adullamite',\n",
              " 'After',\n",
              " 'Aholibamah',\n",
              " 'Ahuzzath',\n",
              " 'Ajah',\n",
              " 'Akan',\n",
              " 'All',\n",
              " 'Allonbachuth',\n",
              " 'Almighty',\n",
              " 'Almodad',\n",
              " 'Also',\n",
              " 'Alvah',\n",
              " 'Alvan',\n",
              " 'Am',\n",
              " 'Amal',\n",
              " 'Amalek',\n",
              " 'Amalekites',\n",
              " 'Ammon',\n",
              " 'Amorite',\n",
              " 'Amorites',\n",
              " 'Amraphel',\n",
              " 'An',\n",
              " 'Anah',\n",
              " 'Anamim',\n",
              " 'And',\n",
              " 'Aner',\n",
              " 'Angel',\n",
              " 'Appoint',\n",
              " 'Aram',\n",
              " 'Aran',\n",
              " 'Ararat',\n",
              " 'Arbah',\n",
              " 'Ard',\n",
              " 'Are',\n",
              " 'Areli',\n",
              " 'Arioch',\n",
              " 'Arise',\n",
              " 'Arkite',\n",
              " 'Arodi',\n",
              " 'Arphaxad',\n",
              " 'Art',\n",
              " 'Arvadite',\n",
              " 'As',\n",
              " 'Asenath',\n",
              " 'Ashbel',\n",
              " 'Asher',\n",
              " 'Ashkenaz',\n",
              " 'Ashteroth',\n",
              " 'Ask',\n",
              " 'Asshur',\n",
              " 'Asshurim',\n",
              " 'Assyr',\n",
              " 'Assyria',\n",
              " 'At',\n",
              " 'Atad',\n",
              " 'Avith',\n",
              " 'Baalhanan',\n",
              " 'Babel',\n",
              " 'Bashemath',\n",
              " 'Be',\n",
              " 'Because',\n",
              " 'Becher',\n",
              " 'Bedad',\n",
              " 'Beeri',\n",
              " 'Beerlahairoi',\n",
              " 'Beersheba',\n",
              " 'Behold',\n",
              " 'Bela',\n",
              " 'Belah',\n",
              " 'Benam',\n",
              " 'Benjamin',\n",
              " 'Beno',\n",
              " 'Beor',\n",
              " 'Bera',\n",
              " 'Bered',\n",
              " 'Beriah',\n",
              " 'Bethel',\n",
              " 'Bethlehem',\n",
              " 'Bethuel',\n",
              " 'Beware',\n",
              " 'Bilhah',\n",
              " 'Bilhan',\n",
              " 'Binding',\n",
              " 'Birsha',\n",
              " 'Bless',\n",
              " 'Blessed',\n",
              " 'Both',\n",
              " 'Bow',\n",
              " 'Bozrah',\n",
              " 'Bring',\n",
              " 'But',\n",
              " 'Buz',\n",
              " 'By',\n",
              " 'Cain',\n",
              " 'Cainan',\n",
              " 'Calah',\n",
              " 'Calneh',\n",
              " 'Can',\n",
              " 'Cana',\n",
              " 'Canaan',\n",
              " 'Canaanite',\n",
              " 'Canaanites',\n",
              " 'Canaanitish',\n",
              " 'Caphtorim',\n",
              " 'Carmi',\n",
              " 'Casluhim',\n",
              " 'Cast',\n",
              " 'Cause',\n",
              " 'Chaldees',\n",
              " 'Chedorlaomer',\n",
              " 'Cheran',\n",
              " 'Cherubims',\n",
              " 'Chesed',\n",
              " 'Chezib',\n",
              " 'Come',\n",
              " 'Cursed',\n",
              " 'Cush',\n",
              " 'Damascus',\n",
              " 'Dan',\n",
              " 'Day',\n",
              " 'Deborah',\n",
              " 'Dedan',\n",
              " 'Deliver',\n",
              " 'Diklah',\n",
              " 'Din',\n",
              " 'Dinah',\n",
              " 'Dinhabah',\n",
              " 'Discern',\n",
              " 'Dishan',\n",
              " 'Dishon',\n",
              " 'Do',\n",
              " 'Dodanim',\n",
              " 'Dothan',\n",
              " 'Drink',\n",
              " 'Duke',\n",
              " 'Dumah',\n",
              " 'Earth',\n",
              " 'Ebal',\n",
              " 'Eber',\n",
              " 'Edar',\n",
              " 'Eden',\n",
              " 'Edom',\n",
              " 'Edomites',\n",
              " 'Egy',\n",
              " 'Egypt',\n",
              " 'Egyptia',\n",
              " 'Egyptian',\n",
              " 'Egyptians',\n",
              " 'Ehi',\n",
              " 'Elah',\n",
              " 'Elam',\n",
              " 'Elbethel',\n",
              " 'Eldaah',\n",
              " 'EleloheIsrael',\n",
              " 'Eliezer',\n",
              " 'Eliphaz',\n",
              " 'Elishah',\n",
              " 'Ellasar',\n",
              " 'Elon',\n",
              " 'Elparan',\n",
              " 'Emins',\n",
              " 'En',\n",
              " 'Enmishpat',\n",
              " 'Eno',\n",
              " 'Enoch',\n",
              " 'Enos',\n",
              " 'Ephah',\n",
              " 'Epher',\n",
              " 'Ephra',\n",
              " 'Ephraim',\n",
              " 'Ephrath',\n",
              " 'Ephron',\n",
              " 'Er',\n",
              " 'Erech',\n",
              " 'Eri',\n",
              " 'Es',\n",
              " 'Esau',\n",
              " 'Escape',\n",
              " 'Esek',\n",
              " 'Eshban',\n",
              " 'Eshcol',\n",
              " 'Ethiopia',\n",
              " 'Euphrat',\n",
              " 'Euphrates',\n",
              " 'Eve',\n",
              " 'Even',\n",
              " 'Every',\n",
              " 'Except',\n",
              " 'Ezbon',\n",
              " 'Ezer',\n",
              " 'Fear',\n",
              " 'Feed',\n",
              " 'Fifteen',\n",
              " 'Fill',\n",
              " 'For',\n",
              " 'Forasmuch',\n",
              " 'Forgive',\n",
              " 'From',\n",
              " 'Fulfil',\n",
              " 'G',\n",
              " 'Gad',\n",
              " 'Gaham',\n",
              " 'Galeed',\n",
              " 'Gatam',\n",
              " 'Gather',\n",
              " 'Gaza',\n",
              " 'Gentiles',\n",
              " 'Gera',\n",
              " 'Gerar',\n",
              " 'Gershon',\n",
              " 'Get',\n",
              " 'Gether',\n",
              " 'Gihon',\n",
              " 'Gilead',\n",
              " 'Girgashites',\n",
              " 'Girgasite',\n",
              " 'Give',\n",
              " 'Go',\n",
              " 'God',\n",
              " 'Gomer',\n",
              " 'Gomorrah',\n",
              " 'Goshen',\n",
              " 'Guni',\n",
              " 'Hadad',\n",
              " 'Hadar',\n",
              " 'Hadoram',\n",
              " 'Hagar',\n",
              " 'Haggi',\n",
              " 'Hai',\n",
              " 'Ham',\n",
              " 'Hamathite',\n",
              " 'Hamor',\n",
              " 'Hamul',\n",
              " 'Hanoch',\n",
              " 'Happy',\n",
              " 'Haran',\n",
              " 'Hast',\n",
              " 'Haste',\n",
              " 'Have',\n",
              " 'Havilah',\n",
              " 'Hazarmaveth',\n",
              " 'Hazezontamar',\n",
              " 'Hazo',\n",
              " 'He',\n",
              " 'Hear',\n",
              " 'Heaven',\n",
              " 'Heber',\n",
              " 'Hebrew',\n",
              " 'Hebrews',\n",
              " 'Hebron',\n",
              " 'Hemam',\n",
              " 'Hemdan',\n",
              " 'Here',\n",
              " 'Hereby',\n",
              " 'Heth',\n",
              " 'Hezron',\n",
              " 'Hiddekel',\n",
              " 'Hinder',\n",
              " 'Hirah',\n",
              " 'His',\n",
              " 'Hitti',\n",
              " 'Hittite',\n",
              " 'Hittites',\n",
              " 'Hivite',\n",
              " 'Hobah',\n",
              " 'Hori',\n",
              " 'Horite',\n",
              " 'Horites',\n",
              " 'How',\n",
              " 'Hul',\n",
              " 'Huppim',\n",
              " 'Husham',\n",
              " 'Hushim',\n",
              " 'Huz',\n",
              " 'I',\n",
              " 'If',\n",
              " 'In',\n",
              " 'Irad',\n",
              " 'Iram',\n",
              " 'Is',\n",
              " 'Isa',\n",
              " 'Isaac',\n",
              " 'Iscah',\n",
              " 'Ishbak',\n",
              " 'Ishmael',\n",
              " 'Ishmeelites',\n",
              " 'Ishuah',\n",
              " 'Isra',\n",
              " 'Israel',\n",
              " 'Issachar',\n",
              " 'Isui',\n",
              " 'It',\n",
              " 'Ithran',\n",
              " 'Jaalam',\n",
              " 'Jabal',\n",
              " 'Jabbok',\n",
              " 'Jac',\n",
              " 'Jachin',\n",
              " 'Jacob',\n",
              " 'Jahleel',\n",
              " 'Jahzeel',\n",
              " 'Jamin',\n",
              " 'Japhe',\n",
              " 'Japheth',\n",
              " 'Jared',\n",
              " 'Javan',\n",
              " 'Jebusite',\n",
              " 'Jebusites',\n",
              " 'Jegarsahadutha',\n",
              " 'Jehovahjireh',\n",
              " 'Jemuel',\n",
              " 'Jerah',\n",
              " 'Jetheth',\n",
              " 'Jetur',\n",
              " 'Jeush',\n",
              " 'Jezer',\n",
              " 'Jidlaph',\n",
              " 'Jimnah',\n",
              " 'Job',\n",
              " 'Jobab',\n",
              " 'Jokshan',\n",
              " 'Joktan',\n",
              " 'Jordan',\n",
              " 'Joseph',\n",
              " 'Jubal',\n",
              " 'Judah',\n",
              " 'Judge',\n",
              " 'Judith',\n",
              " 'Kadesh',\n",
              " 'Kadmonites',\n",
              " 'Karnaim',\n",
              " 'Kedar',\n",
              " 'Kedemah',\n",
              " 'Kemuel',\n",
              " 'Kenaz',\n",
              " 'Kenites',\n",
              " 'Kenizzites',\n",
              " 'Keturah',\n",
              " 'Kiriathaim',\n",
              " 'Kirjatharba',\n",
              " 'Kittim',\n",
              " 'Know',\n",
              " 'Kohath',\n",
              " 'Kor',\n",
              " 'Korah',\n",
              " 'LO',\n",
              " 'LORD',\n",
              " 'Laban',\n",
              " 'Lahairoi',\n",
              " 'Lamech',\n",
              " 'Lasha',\n",
              " 'Lay',\n",
              " 'Leah',\n",
              " 'Lehabim',\n",
              " 'Lest',\n",
              " 'Let',\n",
              " 'Letushim',\n",
              " 'Leummim',\n",
              " 'Levi',\n",
              " 'Lie',\n",
              " 'Lift',\n",
              " 'Lo',\n",
              " 'Look',\n",
              " 'Lot',\n",
              " 'Lotan',\n",
              " 'Lud',\n",
              " 'Ludim',\n",
              " 'Luz',\n",
              " 'Maachah',\n",
              " 'Machir',\n",
              " 'Machpelah',\n",
              " 'Madai',\n",
              " 'Magdiel',\n",
              " 'Magog',\n",
              " 'Mahalaleel',\n",
              " 'Mahalath',\n",
              " 'Mahanaim',\n",
              " 'Make',\n",
              " 'Malchiel',\n",
              " 'Male',\n",
              " 'Mam',\n",
              " 'Mamre',\n",
              " 'Man',\n",
              " 'Manahath',\n",
              " 'Manass',\n",
              " 'Manasseh',\n",
              " 'Mash',\n",
              " 'Masrekah',\n",
              " 'Massa',\n",
              " 'Matred',\n",
              " 'Me',\n",
              " 'Medan',\n",
              " 'Mehetabel',\n",
              " 'Mehujael',\n",
              " 'Melchizedek',\n",
              " 'Merari',\n",
              " 'Mesha',\n",
              " 'Meshech',\n",
              " 'Mesopotamia',\n",
              " 'Methusa',\n",
              " 'Methusael',\n",
              " 'Methuselah',\n",
              " 'Mezahab',\n",
              " 'Mibsam',\n",
              " 'Mibzar',\n",
              " 'Midian',\n",
              " 'Midianites',\n",
              " 'Milcah',\n",
              " 'Mishma',\n",
              " 'Mizpah',\n",
              " 'Mizraim',\n",
              " 'Mizz',\n",
              " 'Moab',\n",
              " 'Moabites',\n",
              " 'Moreh',\n",
              " 'Moreover',\n",
              " 'Moriah',\n",
              " 'Muppim',\n",
              " 'My',\n",
              " 'Naamah',\n",
              " 'Naaman',\n",
              " 'Nahath',\n",
              " 'Nahor',\n",
              " 'Naphish',\n",
              " 'Naphtali',\n",
              " 'Naphtuhim',\n",
              " 'Nay',\n",
              " 'Nebajoth',\n",
              " 'Neither',\n",
              " 'Night',\n",
              " 'Nimrod',\n",
              " 'Nineveh',\n",
              " 'Noah',\n",
              " 'Nod',\n",
              " 'Not',\n",
              " 'Now',\n",
              " 'O',\n",
              " 'Obal',\n",
              " 'Of',\n",
              " 'Oh',\n",
              " 'Ohad',\n",
              " 'Omar',\n",
              " 'On',\n",
              " 'Onam',\n",
              " 'Onan',\n",
              " 'Only',\n",
              " 'Ophir',\n",
              " 'Our',\n",
              " 'Out',\n",
              " 'Padan',\n",
              " 'Padanaram',\n",
              " 'Paran',\n",
              " 'Pass',\n",
              " 'Pathrusim',\n",
              " 'Pau',\n",
              " 'Peace',\n",
              " 'Peleg',\n",
              " 'Peniel',\n",
              " 'Penuel',\n",
              " 'Peradventure',\n",
              " 'Perizzit',\n",
              " 'Perizzite',\n",
              " 'Perizzites',\n",
              " 'Phallu',\n",
              " 'Phara',\n",
              " 'Pharaoh',\n",
              " 'Pharez',\n",
              " 'Phichol',\n",
              " 'Philistim',\n",
              " 'Philistines',\n",
              " 'Phut',\n",
              " 'Phuvah',\n",
              " 'Pildash',\n",
              " 'Pinon',\n",
              " 'Pison',\n",
              " 'Potiphar',\n",
              " 'Potipherah',\n",
              " 'Put',\n",
              " 'Raamah',\n",
              " 'Rachel',\n",
              " 'Rameses',\n",
              " 'Rebek',\n",
              " 'Rebekah',\n",
              " 'Rehoboth',\n",
              " 'Remain',\n",
              " 'Rephaims',\n",
              " 'Resen',\n",
              " 'Return',\n",
              " 'Reu',\n",
              " 'Reub',\n",
              " 'Reuben',\n",
              " 'Reuel',\n",
              " 'Reumah',\n",
              " 'Riphath',\n",
              " 'Rosh',\n",
              " 'Sabtah',\n",
              " 'Sabtech',\n",
              " 'Said',\n",
              " 'Salah',\n",
              " 'Salem',\n",
              " 'Samlah',\n",
              " 'Sarah',\n",
              " 'Sarai',\n",
              " 'Saul',\n",
              " 'Save',\n",
              " 'Say',\n",
              " 'Se',\n",
              " 'Seba',\n",
              " 'See',\n",
              " 'Seeing',\n",
              " 'Seir',\n",
              " 'Sell',\n",
              " 'Send',\n",
              " 'Sephar',\n",
              " 'Serah',\n",
              " 'Sered',\n",
              " 'Serug',\n",
              " 'Set',\n",
              " 'Seth',\n",
              " 'Shalem',\n",
              " 'Shall',\n",
              " 'Shalt',\n",
              " 'Shammah',\n",
              " 'Shaul',\n",
              " 'Shaveh',\n",
              " 'She',\n",
              " 'Sheba',\n",
              " 'Shebah',\n",
              " 'Shechem',\n",
              " 'Shed',\n",
              " 'Shel',\n",
              " 'Shelah',\n",
              " 'Sheleph',\n",
              " 'Shem',\n",
              " 'Shemeber',\n",
              " 'Shepho',\n",
              " 'Shillem',\n",
              " 'Shiloh',\n",
              " 'Shimron',\n",
              " 'Shinab',\n",
              " 'Shinar',\n",
              " 'Shobal',\n",
              " 'Should',\n",
              " 'Shuah',\n",
              " 'Shuni',\n",
              " 'Shur',\n",
              " 'Sichem',\n",
              " 'Siddim',\n",
              " 'Sidon',\n",
              " 'Simeon',\n",
              " 'Sinite',\n",
              " 'Sitnah',\n",
              " 'Slay',\n",
              " 'So',\n",
              " 'Sod',\n",
              " 'Sodom',\n",
              " 'Sojourn',\n",
              " 'Some',\n",
              " 'Spake',\n",
              " 'Speak',\n",
              " 'Spirit',\n",
              " 'Stand',\n",
              " 'Succoth',\n",
              " 'Surely',\n",
              " 'Swear',\n",
              " 'Syrian',\n",
              " 'Take',\n",
              " 'Tamar',\n",
              " 'Tarshish',\n",
              " 'Tebah',\n",
              " 'Tell',\n",
              " 'Tema',\n",
              " 'Teman',\n",
              " 'Temani',\n",
              " 'Terah',\n",
              " 'Thahash',\n",
              " 'That',\n",
              " 'The',\n",
              " 'Then',\n",
              " 'There',\n",
              " 'Therefore',\n",
              " 'These',\n",
              " 'They',\n",
              " 'Thirty',\n",
              " 'This',\n",
              " 'Thorns',\n",
              " 'Thou',\n",
              " 'Thus',\n",
              " 'Thy',\n",
              " 'Tidal',\n",
              " 'Timna',\n",
              " 'Timnah',\n",
              " 'Timnath',\n",
              " 'Tiras',\n",
              " 'To',\n",
              " 'Togarmah',\n",
              " 'Tola',\n",
              " 'Tubal',\n",
              " 'Tubalcain',\n",
              " 'Twelve',\n",
              " 'Two',\n",
              " 'Unstable',\n",
              " 'Until',\n",
              " 'Unto',\n",
              " 'Up',\n",
              " 'Upon',\n",
              " 'Ur',\n",
              " 'Uz',\n",
              " 'Uzal',\n",
              " 'We',\n",
              " 'What',\n",
              " 'When',\n",
              " 'Whence',\n",
              " 'Where',\n",
              " 'Whereas',\n",
              " 'Wherefore',\n",
              " 'Which',\n",
              " 'While',\n",
              " 'Who',\n",
              " 'Whose',\n",
              " 'Whoso',\n",
              " 'Why',\n",
              " 'Wilt',\n",
              " 'With',\n",
              " 'Woman',\n",
              " 'Ye',\n",
              " 'Yea',\n",
              " 'Yet',\n",
              " 'Zaavan',\n",
              " 'Zaphnathpaaneah',\n",
              " 'Zar',\n",
              " 'Zarah',\n",
              " 'Zeboiim',\n",
              " 'Zeboim',\n",
              " 'Zebul',\n",
              " 'Zebulun',\n",
              " 'Zemarite',\n",
              " 'Zepho',\n",
              " 'Zerah',\n",
              " 'Zibeon',\n",
              " 'Zidon',\n",
              " 'Zillah',\n",
              " 'Zilpah',\n",
              " 'Zimran',\n",
              " 'Ziphion',\n",
              " 'Zo',\n",
              " 'Zoar',\n",
              " 'Zohar',\n",
              " 'Zuzims',\n",
              " 'a',\n",
              " 'abated',\n",
              " 'abide',\n",
              " 'able',\n",
              " 'abode',\n",
              " 'abomination',\n",
              " 'about',\n",
              " 'above',\n",
              " 'abroad',\n",
              " 'absent',\n",
              " 'abundantly',\n",
              " 'accept',\n",
              " 'accepted',\n",
              " 'according',\n",
              " 'acknowledged',\n",
              " 'activity',\n",
              " 'add',\n",
              " 'adder',\n",
              " 'afar',\n",
              " 'afflict',\n",
              " 'affliction',\n",
              " 'afraid',\n",
              " 'after',\n",
              " 'afterward',\n",
              " 'afterwards',\n",
              " 'aga',\n",
              " 'again',\n",
              " 'against',\n",
              " 'age',\n",
              " 'aileth',\n",
              " 'air',\n",
              " 'al',\n",
              " 'alive',\n",
              " 'all',\n",
              " 'almon',\n",
              " 'alo',\n",
              " 'alone',\n",
              " 'aloud',\n",
              " 'also',\n",
              " 'altar',\n",
              " 'altogether',\n",
              " 'always',\n",
              " 'am',\n",
              " 'among',\n",
              " 'amongst',\n",
              " 'an',\n",
              " 'and',\n",
              " 'angel',\n",
              " 'angels',\n",
              " 'anger',\n",
              " 'angry',\n",
              " 'anguish',\n",
              " 'anointedst',\n",
              " 'anoth',\n",
              " 'another',\n",
              " 'answer',\n",
              " 'answered',\n",
              " 'any',\n",
              " 'anything',\n",
              " 'appe',\n",
              " 'appear',\n",
              " 'appeared',\n",
              " 'appease',\n",
              " 'appoint',\n",
              " 'appointed',\n",
              " 'aprons',\n",
              " 'archer',\n",
              " 'archers',\n",
              " 'are',\n",
              " 'arise',\n",
              " 'ark',\n",
              " 'armed',\n",
              " 'arms',\n",
              " 'army',\n",
              " 'arose',\n",
              " 'arrayed',\n",
              " 'art',\n",
              " 'artificer',\n",
              " 'as',\n",
              " 'ascending',\n",
              " 'ash',\n",
              " 'ashamed',\n",
              " 'ask',\n",
              " 'asked',\n",
              " 'asketh',\n",
              " 'ass',\n",
              " 'assembly',\n",
              " 'asses',\n",
              " 'assigned',\n",
              " 'asswaged',\n",
              " 'at',\n",
              " 'attained',\n",
              " 'audience',\n",
              " 'avenged',\n",
              " 'aw',\n",
              " 'awaked',\n",
              " 'away',\n",
              " 'awoke',\n",
              " 'back',\n",
              " 'backward',\n",
              " 'bad',\n",
              " 'bade',\n",
              " 'badest',\n",
              " 'badne',\n",
              " 'bak',\n",
              " 'bake',\n",
              " 'bakemeats',\n",
              " 'baker',\n",
              " 'bakers',\n",
              " 'balm',\n",
              " 'bands',\n",
              " 'bank',\n",
              " 'bare',\n",
              " 'barr',\n",
              " 'barren',\n",
              " 'basket',\n",
              " 'baskets',\n",
              " 'battle',\n",
              " 'bdellium',\n",
              " 'be',\n",
              " 'bear',\n",
              " 'beari',\n",
              " 'bearing',\n",
              " 'beast',\n",
              " 'beasts',\n",
              " 'beautiful',\n",
              " 'became',\n",
              " 'because',\n",
              " 'become',\n",
              " 'bed',\n",
              " 'been',\n",
              " 'befall',\n",
              " 'befell',\n",
              " 'before',\n",
              " 'began',\n",
              " 'begat',\n",
              " 'beget',\n",
              " 'begettest',\n",
              " 'begin',\n",
              " 'beginning',\n",
              " 'begotten',\n",
              " 'beguiled',\n",
              " 'beheld',\n",
              " 'behind',\n",
              " 'behold',\n",
              " 'being',\n",
              " 'believed',\n",
              " 'belly',\n",
              " 'belong',\n",
              " 'beneath',\n",
              " 'bereaved',\n",
              " 'beside',\n",
              " 'besides',\n",
              " 'besought',\n",
              " 'best',\n",
              " 'betimes',\n",
              " 'better',\n",
              " 'between',\n",
              " 'betwixt',\n",
              " 'beyond',\n",
              " 'binding',\n",
              " 'bird',\n",
              " 'birds',\n",
              " 'birthday',\n",
              " 'birthright',\n",
              " 'biteth',\n",
              " 'bitter',\n",
              " 'blame',\n",
              " 'blameless',\n",
              " 'blasted',\n",
              " 'bless',\n",
              " 'blessed',\n",
              " 'blesseth',\n",
              " 'blessi',\n",
              " 'blessing',\n",
              " 'blessings',\n",
              " 'blindness',\n",
              " 'blood',\n",
              " 'blossoms',\n",
              " 'bodies',\n",
              " 'boldly',\n",
              " 'bondman',\n",
              " 'bondmen',\n",
              " 'bondwoman',\n",
              " 'bone',\n",
              " 'bones',\n",
              " 'book',\n",
              " 'booths',\n",
              " 'border',\n",
              " 'borders',\n",
              " 'born',\n",
              " 'bosom',\n",
              " 'both',\n",
              " 'bottle',\n",
              " 'bou',\n",
              " 'boug',\n",
              " 'bough',\n",
              " 'bought',\n",
              " 'bound',\n",
              " 'bow',\n",
              " 'bowed',\n",
              " 'bowels',\n",
              " 'bowing',\n",
              " 'boys',\n",
              " 'bracelets',\n",
              " 'branches',\n",
              " 'brass',\n",
              " 'bre',\n",
              " 'breach',\n",
              " 'bread',\n",
              " 'breadth',\n",
              " 'break',\n",
              " 'breaketh',\n",
              " 'breaking',\n",
              " 'breasts',\n",
              " 'breath',\n",
              " 'breathed',\n",
              " 'breed',\n",
              " 'brethren',\n",
              " 'brick',\n",
              " 'brimstone',\n",
              " 'bring',\n",
              " 'brink',\n",
              " 'broken',\n",
              " 'brook',\n",
              " 'broth',\n",
              " 'brother',\n",
              " 'brought',\n",
              " 'brown',\n",
              " 'bruise',\n",
              " 'budded',\n",
              " 'build',\n",
              " 'builded',\n",
              " 'built',\n",
              " 'bulls',\n",
              " 'bundle',\n",
              " 'bundles',\n",
              " 'burdens',\n",
              " 'buried',\n",
              " 'burn',\n",
              " 'burning',\n",
              " 'burnt',\n",
              " 'bury',\n",
              " 'buryingplace',\n",
              " 'business',\n",
              " 'but',\n",
              " 'butler',\n",
              " 'butlers',\n",
              " 'butlership',\n",
              " 'butter',\n",
              " 'buy',\n",
              " 'by',\n",
              " 'cakes',\n",
              " 'calf',\n",
              " 'call',\n",
              " 'called',\n",
              " 'came',\n",
              " 'camel',\n",
              " 'camels',\n",
              " 'camest',\n",
              " 'can',\n",
              " 'cannot',\n",
              " 'canst',\n",
              " 'captain',\n",
              " 'captive',\n",
              " 'captives',\n",
              " 'carcases',\n",
              " 'carried',\n",
              " 'carry',\n",
              " 'cast',\n",
              " 'castles',\n",
              " 'catt',\n",
              " 'cattle',\n",
              " 'caught',\n",
              " 'cause',\n",
              " 'caused',\n",
              " 'cave',\n",
              " 'cease',\n",
              " 'ceased',\n",
              " 'certain',\n",
              " 'certainly',\n",
              " 'chain',\n",
              " 'chamber',\n",
              " 'change',\n",
              " 'changed',\n",
              " 'changes',\n",
              " 'charge',\n",
              " 'charged',\n",
              " 'chariot',\n",
              " 'chariots',\n",
              " 'chesnut',\n",
              " 'chi',\n",
              " 'chief',\n",
              " 'child',\n",
              " 'childless',\n",
              " 'childr',\n",
              " 'children',\n",
              " 'chode',\n",
              " 'choice',\n",
              " 'chose',\n",
              " 'circumcis',\n",
              " 'circumcise',\n",
              " 'circumcised',\n",
              " 'citi',\n",
              " 'cities',\n",
              " 'city',\n",
              " 'clave',\n",
              " 'clean',\n",
              " 'clear',\n",
              " 'cleave',\n",
              " 'clo',\n",
              " 'closed',\n",
              " 'clothed',\n",
              " 'clothes',\n",
              " 'cloud',\n",
              " 'clusters',\n",
              " 'co',\n",
              " 'coat',\n",
              " 'coats',\n",
              " 'coffin',\n",
              " 'cold',\n",
              " ...]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to obtain the vocabulary of a given corpora (the unique words and punctuations)\n",
        "sorted(set(text3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cda67e5",
      "metadata": {
        "id": "1cda67e5",
        "outputId": "2c64df27-8398-4c62-b543-45fc294d647e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2789\n",
            "44764\n",
            "6.230453042623537\n"
          ]
        }
      ],
      "source": [
        "print(len(set(text3)))\n",
        "print(len(text3))\n",
        "print(len(set(text3)) / len(text3) * 100)\n",
        "# what do you reveal comparing then number of tokens with the vocabulary number?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e706fd0",
      "metadata": {
        "id": "5e706fd0",
        "outputId": "58321d18-7199-47b8-bf74-e29343fc345d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "484"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to compute the number of occurances of a specific word\n",
        "text3.count(\"I\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a7446d",
      "metadata": {
        "id": "b3a7446d"
      },
      "source": [
        "# Let's think about Text\n",
        "\n",
        "A text is a sequence of words and character (tokens) separated by white spaces, new lines, ...\n",
        "We can simply represent any corpora as a sequence of tokens so in python it is simply a list. This is how nltk represents text corporas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c54d9eca",
      "metadata": {
        "id": "c54d9eca",
        "outputId": "9d2f81a8-79bd-4b14-becc-b2b96037c986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "sent1 = ['Call', 'me', 'Ishmael', '.']\n",
        "\n",
        "# to see the total number of tokens\n",
        "print(len(sent1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639a6a4d",
      "metadata": {
        "id": "639a6a4d",
        "outputId": "bc072851-c1d6-466a-beb1-95cac1c26e78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'family',\n",
              " 'of',\n",
              " 'Dashwood',\n",
              " 'had',\n",
              " 'long',\n",
              " 'been',\n",
              " 'settled',\n",
              " 'in',\n",
              " 'Sussex',\n",
              " '.']"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f68201",
      "metadata": {
        "id": "a0f68201",
        "outputId": "fb45c551-0f3d-458e-ee34-8b8af2922940"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['In',\n",
              " 'the',\n",
              " 'beginning',\n",
              " 'God',\n",
              " 'created',\n",
              " 'the',\n",
              " 'heaven',\n",
              " 'and',\n",
              " 'the',\n",
              " 'earth',\n",
              " '.']"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b77e0d",
      "metadata": {
        "id": "84b77e0d",
        "outputId": "0d7bf174-1d22-44b4-e9a0-078d7e10657d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'family',\n",
              " 'of',\n",
              " 'Dashwood',\n",
              " 'had',\n",
              " 'long',\n",
              " 'been',\n",
              " 'settled',\n",
              " 'in',\n",
              " 'Sussex',\n",
              " '.',\n",
              " 'In',\n",
              " 'the',\n",
              " 'beginning',\n",
              " 'God',\n",
              " 'created',\n",
              " 'the',\n",
              " 'heaven',\n",
              " 'and',\n",
              " 'the',\n",
              " 'earth',\n",
              " '.']"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to concatenate two sentences (lists)\n",
        "sent2 + sent3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f762759",
      "metadata": {
        "id": "6f762759",
        "outputId": "c157530c-e00f-46e8-9848-c1ff8a78f66c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Call', 'me', 'Ishmael', '.', 'Some']"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to add new token to a sentence\n",
        "sent1.append('Some')\n",
        "sent1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abe45793",
      "metadata": {
        "id": "abe45793",
        "outputId": "1a854abd-cbad-41be-a14e-dd5c789a7b28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'awaken'"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to index a sentence (list) by index\n",
        "text4[173]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690511fd",
      "metadata": {
        "id": "690511fd",
        "outputId": "91d92f01-400c-4eab-d396-5ad8707bdbb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "173"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to get the first index of a specific word\n",
        "text4.index('awaken')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a00a1eea",
      "metadata": {
        "id": "a00a1eea",
        "outputId": "4899d1e2-27ec-4100-f13a-6407264b7780"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['U86',\n",
              " 'thats',\n",
              " 'why',\n",
              " 'something',\n",
              " 'like',\n",
              " 'gamefly',\n",
              " 'is',\n",
              " 'so',\n",
              " 'good',\n",
              " 'because',\n",
              " 'you',\n",
              " 'can',\n",
              " 'actually',\n",
              " 'play',\n",
              " 'a',\n",
              " 'full',\n",
              " 'game',\n",
              " 'without',\n",
              " 'buying',\n",
              " 'it']"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can use list slicing to get a part of the text\n",
        "text5[16715:16735]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecabbace",
      "metadata": {
        "id": "ecabbace",
        "outputId": "767dfd41-7732-439f-941a-1e2b0e52fa74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'nltk.probability.FreqDist'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(',', 18713),\n",
              " ('the', 13721),\n",
              " ('.', 6862),\n",
              " ('of', 6536),\n",
              " ('and', 6024),\n",
              " ('a', 4569),\n",
              " ('to', 4542),\n",
              " (';', 4072),\n",
              " ('in', 3916),\n",
              " ('that', 2982)]"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To calculate the word count of a corpora\n",
        "fdist1 = FreqDist(text1)\n",
        "print(type(fdist1))\n",
        "fdist1.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34e79117",
      "metadata": {
        "id": "34e79117",
        "outputId": "3b8d557c-6246-4827-9d5f-9606292c1659"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "906"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fdist1['whale']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3599fbb",
      "metadata": {
        "id": "f3599fbb",
        "outputId": "0230a8d0-01fa-4b89-e420-c03b9a35fb8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['irresistibleness',\n",
              " 'undiscriminating',\n",
              " 'responsibilities',\n",
              " 'simultaneousness',\n",
              " 'uncomfortableness',\n",
              " 'cannibalistically',\n",
              " 'preternaturalness',\n",
              " 'indispensableness',\n",
              " 'apprehensiveness',\n",
              " 'circumnavigation',\n",
              " 'uninterpenetratingly',\n",
              " 'physiognomically',\n",
              " 'comprehensiveness',\n",
              " 'circumnavigating',\n",
              " 'subterraneousness',\n",
              " 'indiscriminately',\n",
              " 'circumnavigations',\n",
              " 'supernaturalness',\n",
              " 'Physiognomically',\n",
              " 'hermaphroditical',\n",
              " 'CIRCUMNAVIGATION',\n",
              " 'uncompromisedness',\n",
              " 'characteristically',\n",
              " 'superstitiousness']"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To filter words based on the word length\n",
        "# let's get the words having more than 15 character\n",
        "long_words = [w for w in set(text1) if len(w) > 15]\n",
        "long_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "607a2448",
      "metadata": {
        "id": "607a2448",
        "outputId": "f115de50-dadc-4c3a-b638-7ea9cb63de90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.', 'i', 'you', 'hi', 'I', ',', '?', 'JOIN', 'PART', 'lol', 'a', 'to', 'the']"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# what about filtering based on the word frequency in the corpora?\n",
        "fdist5 = FreqDist(text5)\n",
        "common_words = [w for w in set(text5) if fdist5[w] > 500]\n",
        "common_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "811c9024",
      "metadata": {
        "id": "811c9024",
        "outputId": "621a911b-5997-476a-bbd6-339e50de2d55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# python built-in string comaprison operators\n",
        "\n",
        "# checks if string starts with sub-string\n",
        "print(\"omar\".startswith('o'))\n",
        "# checks if string ends with sub-string\n",
        "print(\"omar\".endswith('r'))\n",
        "# checks if string is sub-string of another\n",
        "print(\"ma\" in \"omar\")\n",
        "# checks if all characters in the string are lowercase\n",
        "print(\"omar\".islower())\n",
        "# checks if all characters in the string are uppercase\n",
        "print(\"OMAR\".isupper())\n",
        "# checks if all the characters in a string are alphabetic characters (a-z) only\n",
        "print(\"omar\".isalpha())\n",
        "# checks if all the characters are alphanumeric (a-z, 0-9) only\n",
        "print(\"omar1\".isalnum())\n",
        "# checks if all the characters are numeric (0-9) only\n",
        "print(\"123\".isdigit())\n",
        "# checks if the string is title-cased. (all words in a string begin with uppercase letters and the remaining characters are lowercase letters)\n",
        "print(\"Introduction To Python\".istitle())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e3bd30e",
      "metadata": {},
      "source": [
        "# Towards Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd3c08c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Natural Language Toolkit\n",
        "# !pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c22055",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package chat80 to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package swadesh to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /home/omarsgalal/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('book')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "502f884e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
          ]
        }
      ],
      "source": [
        "from nltk.book import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b6109b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "nltk.text.Text"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "type(text1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aecd8cd4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Text: Moby Dick by Herman Melville 1851>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "text1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a0de5dd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Displaying 11 of 11 matches:\n",
            "ong the former , one was of a most monstrous size . ... This came towards us , \n",
            "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
            "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
            "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
            "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
            "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
            "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
            "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
            "ere to enter upon those still more monstrous stories of them which are to be fo\n",
            "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
            "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n"
          ]
        }
      ],
      "source": [
        "# search for a specific word in a text\n",
        "text1.concordance(\"monstrous\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b1f183",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44764"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# the number of tokens in a given text (words and punctuation symbols)\n",
        "len(text3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3867b180",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['!',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " ',)',\n",
              " '.',\n",
              " '.)',\n",
              " ':',\n",
              " ';',\n",
              " ';)',\n",
              " '?',\n",
              " '?)',\n",
              " 'A',\n",
              " 'Abel',\n",
              " 'Abelmizraim',\n",
              " 'Abidah',\n",
              " 'Abide',\n",
              " 'Abimael',\n",
              " 'Abimelech',\n",
              " 'Abr',\n",
              " 'Abrah',\n",
              " 'Abraham',\n",
              " 'Abram',\n",
              " 'Accad',\n",
              " 'Achbor',\n",
              " 'Adah',\n",
              " 'Adam',\n",
              " 'Adbeel',\n",
              " 'Admah',\n",
              " 'Adullamite',\n",
              " 'After',\n",
              " 'Aholibamah',\n",
              " 'Ahuzzath',\n",
              " 'Ajah',\n",
              " 'Akan',\n",
              " 'All',\n",
              " 'Allonbachuth',\n",
              " 'Almighty',\n",
              " 'Almodad',\n",
              " 'Also',\n",
              " 'Alvah',\n",
              " 'Alvan',\n",
              " 'Am',\n",
              " 'Amal',\n",
              " 'Amalek',\n",
              " 'Amalekites',\n",
              " 'Ammon',\n",
              " 'Amorite',\n",
              " 'Amorites',\n",
              " 'Amraphel',\n",
              " 'An',\n",
              " 'Anah',\n",
              " 'Anamim',\n",
              " 'And',\n",
              " 'Aner',\n",
              " 'Angel',\n",
              " 'Appoint',\n",
              " 'Aram',\n",
              " 'Aran',\n",
              " 'Ararat',\n",
              " 'Arbah',\n",
              " 'Ard',\n",
              " 'Are',\n",
              " 'Areli',\n",
              " 'Arioch',\n",
              " 'Arise',\n",
              " 'Arkite',\n",
              " 'Arodi',\n",
              " 'Arphaxad',\n",
              " 'Art',\n",
              " 'Arvadite',\n",
              " 'As',\n",
              " 'Asenath',\n",
              " 'Ashbel',\n",
              " 'Asher',\n",
              " 'Ashkenaz',\n",
              " 'Ashteroth',\n",
              " 'Ask',\n",
              " 'Asshur',\n",
              " 'Asshurim',\n",
              " 'Assyr',\n",
              " 'Assyria',\n",
              " 'At',\n",
              " 'Atad',\n",
              " 'Avith',\n",
              " 'Baalhanan',\n",
              " 'Babel',\n",
              " 'Bashemath',\n",
              " 'Be',\n",
              " 'Because',\n",
              " 'Becher',\n",
              " 'Bedad',\n",
              " 'Beeri',\n",
              " 'Beerlahairoi',\n",
              " 'Beersheba',\n",
              " 'Behold',\n",
              " 'Bela',\n",
              " 'Belah',\n",
              " 'Benam',\n",
              " 'Benjamin',\n",
              " 'Beno',\n",
              " 'Beor',\n",
              " 'Bera',\n",
              " 'Bered',\n",
              " 'Beriah',\n",
              " 'Bethel',\n",
              " 'Bethlehem',\n",
              " 'Bethuel',\n",
              " 'Beware',\n",
              " 'Bilhah',\n",
              " 'Bilhan',\n",
              " 'Binding',\n",
              " 'Birsha',\n",
              " 'Bless',\n",
              " 'Blessed',\n",
              " 'Both',\n",
              " 'Bow',\n",
              " 'Bozrah',\n",
              " 'Bring',\n",
              " 'But',\n",
              " 'Buz',\n",
              " 'By',\n",
              " 'Cain',\n",
              " 'Cainan',\n",
              " 'Calah',\n",
              " 'Calneh',\n",
              " 'Can',\n",
              " 'Cana',\n",
              " 'Canaan',\n",
              " 'Canaanite',\n",
              " 'Canaanites',\n",
              " 'Canaanitish',\n",
              " 'Caphtorim',\n",
              " 'Carmi',\n",
              " 'Casluhim',\n",
              " 'Cast',\n",
              " 'Cause',\n",
              " 'Chaldees',\n",
              " 'Chedorlaomer',\n",
              " 'Cheran',\n",
              " 'Cherubims',\n",
              " 'Chesed',\n",
              " 'Chezib',\n",
              " 'Come',\n",
              " 'Cursed',\n",
              " 'Cush',\n",
              " 'Damascus',\n",
              " 'Dan',\n",
              " 'Day',\n",
              " 'Deborah',\n",
              " 'Dedan',\n",
              " 'Deliver',\n",
              " 'Diklah',\n",
              " 'Din',\n",
              " 'Dinah',\n",
              " 'Dinhabah',\n",
              " 'Discern',\n",
              " 'Dishan',\n",
              " 'Dishon',\n",
              " 'Do',\n",
              " 'Dodanim',\n",
              " 'Dothan',\n",
              " 'Drink',\n",
              " 'Duke',\n",
              " 'Dumah',\n",
              " 'Earth',\n",
              " 'Ebal',\n",
              " 'Eber',\n",
              " 'Edar',\n",
              " 'Eden',\n",
              " 'Edom',\n",
              " 'Edomites',\n",
              " 'Egy',\n",
              " 'Egypt',\n",
              " 'Egyptia',\n",
              " 'Egyptian',\n",
              " 'Egyptians',\n",
              " 'Ehi',\n",
              " 'Elah',\n",
              " 'Elam',\n",
              " 'Elbethel',\n",
              " 'Eldaah',\n",
              " 'EleloheIsrael',\n",
              " 'Eliezer',\n",
              " 'Eliphaz',\n",
              " 'Elishah',\n",
              " 'Ellasar',\n",
              " 'Elon',\n",
              " 'Elparan',\n",
              " 'Emins',\n",
              " 'En',\n",
              " 'Enmishpat',\n",
              " 'Eno',\n",
              " 'Enoch',\n",
              " 'Enos',\n",
              " 'Ephah',\n",
              " 'Epher',\n",
              " 'Ephra',\n",
              " 'Ephraim',\n",
              " 'Ephrath',\n",
              " 'Ephron',\n",
              " 'Er',\n",
              " 'Erech',\n",
              " 'Eri',\n",
              " 'Es',\n",
              " 'Esau',\n",
              " 'Escape',\n",
              " 'Esek',\n",
              " 'Eshban',\n",
              " 'Eshcol',\n",
              " 'Ethiopia',\n",
              " 'Euphrat',\n",
              " 'Euphrates',\n",
              " 'Eve',\n",
              " 'Even',\n",
              " 'Every',\n",
              " 'Except',\n",
              " 'Ezbon',\n",
              " 'Ezer',\n",
              " 'Fear',\n",
              " 'Feed',\n",
              " 'Fifteen',\n",
              " 'Fill',\n",
              " 'For',\n",
              " 'Forasmuch',\n",
              " 'Forgive',\n",
              " 'From',\n",
              " 'Fulfil',\n",
              " 'G',\n",
              " 'Gad',\n",
              " 'Gaham',\n",
              " 'Galeed',\n",
              " 'Gatam',\n",
              " 'Gather',\n",
              " 'Gaza',\n",
              " 'Gentiles',\n",
              " 'Gera',\n",
              " 'Gerar',\n",
              " 'Gershon',\n",
              " 'Get',\n",
              " 'Gether',\n",
              " 'Gihon',\n",
              " 'Gilead',\n",
              " 'Girgashites',\n",
              " 'Girgasite',\n",
              " 'Give',\n",
              " 'Go',\n",
              " 'God',\n",
              " 'Gomer',\n",
              " 'Gomorrah',\n",
              " 'Goshen',\n",
              " 'Guni',\n",
              " 'Hadad',\n",
              " 'Hadar',\n",
              " 'Hadoram',\n",
              " 'Hagar',\n",
              " 'Haggi',\n",
              " 'Hai',\n",
              " 'Ham',\n",
              " 'Hamathite',\n",
              " 'Hamor',\n",
              " 'Hamul',\n",
              " 'Hanoch',\n",
              " 'Happy',\n",
              " 'Haran',\n",
              " 'Hast',\n",
              " 'Haste',\n",
              " 'Have',\n",
              " 'Havilah',\n",
              " 'Hazarmaveth',\n",
              " 'Hazezontamar',\n",
              " 'Hazo',\n",
              " 'He',\n",
              " 'Hear',\n",
              " 'Heaven',\n",
              " 'Heber',\n",
              " 'Hebrew',\n",
              " 'Hebrews',\n",
              " 'Hebron',\n",
              " 'Hemam',\n",
              " 'Hemdan',\n",
              " 'Here',\n",
              " 'Hereby',\n",
              " 'Heth',\n",
              " 'Hezron',\n",
              " 'Hiddekel',\n",
              " 'Hinder',\n",
              " 'Hirah',\n",
              " 'His',\n",
              " 'Hitti',\n",
              " 'Hittite',\n",
              " 'Hittites',\n",
              " 'Hivite',\n",
              " 'Hobah',\n",
              " 'Hori',\n",
              " 'Horite',\n",
              " 'Horites',\n",
              " 'How',\n",
              " 'Hul',\n",
              " 'Huppim',\n",
              " 'Husham',\n",
              " 'Hushim',\n",
              " 'Huz',\n",
              " 'I',\n",
              " 'If',\n",
              " 'In',\n",
              " 'Irad',\n",
              " 'Iram',\n",
              " 'Is',\n",
              " 'Isa',\n",
              " 'Isaac',\n",
              " 'Iscah',\n",
              " 'Ishbak',\n",
              " 'Ishmael',\n",
              " 'Ishmeelites',\n",
              " 'Ishuah',\n",
              " 'Isra',\n",
              " 'Israel',\n",
              " 'Issachar',\n",
              " 'Isui',\n",
              " 'It',\n",
              " 'Ithran',\n",
              " 'Jaalam',\n",
              " 'Jabal',\n",
              " 'Jabbok',\n",
              " 'Jac',\n",
              " 'Jachin',\n",
              " 'Jacob',\n",
              " 'Jahleel',\n",
              " 'Jahzeel',\n",
              " 'Jamin',\n",
              " 'Japhe',\n",
              " 'Japheth',\n",
              " 'Jared',\n",
              " 'Javan',\n",
              " 'Jebusite',\n",
              " 'Jebusites',\n",
              " 'Jegarsahadutha',\n",
              " 'Jehovahjireh',\n",
              " 'Jemuel',\n",
              " 'Jerah',\n",
              " 'Jetheth',\n",
              " 'Jetur',\n",
              " 'Jeush',\n",
              " 'Jezer',\n",
              " 'Jidlaph',\n",
              " 'Jimnah',\n",
              " 'Job',\n",
              " 'Jobab',\n",
              " 'Jokshan',\n",
              " 'Joktan',\n",
              " 'Jordan',\n",
              " 'Joseph',\n",
              " 'Jubal',\n",
              " 'Judah',\n",
              " 'Judge',\n",
              " 'Judith',\n",
              " 'Kadesh',\n",
              " 'Kadmonites',\n",
              " 'Karnaim',\n",
              " 'Kedar',\n",
              " 'Kedemah',\n",
              " 'Kemuel',\n",
              " 'Kenaz',\n",
              " 'Kenites',\n",
              " 'Kenizzites',\n",
              " 'Keturah',\n",
              " 'Kiriathaim',\n",
              " 'Kirjatharba',\n",
              " 'Kittim',\n",
              " 'Know',\n",
              " 'Kohath',\n",
              " 'Kor',\n",
              " 'Korah',\n",
              " 'LO',\n",
              " 'LORD',\n",
              " 'Laban',\n",
              " 'Lahairoi',\n",
              " 'Lamech',\n",
              " 'Lasha',\n",
              " 'Lay',\n",
              " 'Leah',\n",
              " 'Lehabim',\n",
              " 'Lest',\n",
              " 'Let',\n",
              " 'Letushim',\n",
              " 'Leummim',\n",
              " 'Levi',\n",
              " 'Lie',\n",
              " 'Lift',\n",
              " 'Lo',\n",
              " 'Look',\n",
              " 'Lot',\n",
              " 'Lotan',\n",
              " 'Lud',\n",
              " 'Ludim',\n",
              " 'Luz',\n",
              " 'Maachah',\n",
              " 'Machir',\n",
              " 'Machpelah',\n",
              " 'Madai',\n",
              " 'Magdiel',\n",
              " 'Magog',\n",
              " 'Mahalaleel',\n",
              " 'Mahalath',\n",
              " 'Mahanaim',\n",
              " 'Make',\n",
              " 'Malchiel',\n",
              " 'Male',\n",
              " 'Mam',\n",
              " 'Mamre',\n",
              " 'Man',\n",
              " 'Manahath',\n",
              " 'Manass',\n",
              " 'Manasseh',\n",
              " 'Mash',\n",
              " 'Masrekah',\n",
              " 'Massa',\n",
              " 'Matred',\n",
              " 'Me',\n",
              " 'Medan',\n",
              " 'Mehetabel',\n",
              " 'Mehujael',\n",
              " 'Melchizedek',\n",
              " 'Merari',\n",
              " 'Mesha',\n",
              " 'Meshech',\n",
              " 'Mesopotamia',\n",
              " 'Methusa',\n",
              " 'Methusael',\n",
              " 'Methuselah',\n",
              " 'Mezahab',\n",
              " 'Mibsam',\n",
              " 'Mibzar',\n",
              " 'Midian',\n",
              " 'Midianites',\n",
              " 'Milcah',\n",
              " 'Mishma',\n",
              " 'Mizpah',\n",
              " 'Mizraim',\n",
              " 'Mizz',\n",
              " 'Moab',\n",
              " 'Moabites',\n",
              " 'Moreh',\n",
              " 'Moreover',\n",
              " 'Moriah',\n",
              " 'Muppim',\n",
              " 'My',\n",
              " 'Naamah',\n",
              " 'Naaman',\n",
              " 'Nahath',\n",
              " 'Nahor',\n",
              " 'Naphish',\n",
              " 'Naphtali',\n",
              " 'Naphtuhim',\n",
              " 'Nay',\n",
              " 'Nebajoth',\n",
              " 'Neither',\n",
              " 'Night',\n",
              " 'Nimrod',\n",
              " 'Nineveh',\n",
              " 'Noah',\n",
              " 'Nod',\n",
              " 'Not',\n",
              " 'Now',\n",
              " 'O',\n",
              " 'Obal',\n",
              " 'Of',\n",
              " 'Oh',\n",
              " 'Ohad',\n",
              " 'Omar',\n",
              " 'On',\n",
              " 'Onam',\n",
              " 'Onan',\n",
              " 'Only',\n",
              " 'Ophir',\n",
              " 'Our',\n",
              " 'Out',\n",
              " 'Padan',\n",
              " 'Padanaram',\n",
              " 'Paran',\n",
              " 'Pass',\n",
              " 'Pathrusim',\n",
              " 'Pau',\n",
              " 'Peace',\n",
              " 'Peleg',\n",
              " 'Peniel',\n",
              " 'Penuel',\n",
              " 'Peradventure',\n",
              " 'Perizzit',\n",
              " 'Perizzite',\n",
              " 'Perizzites',\n",
              " 'Phallu',\n",
              " 'Phara',\n",
              " 'Pharaoh',\n",
              " 'Pharez',\n",
              " 'Phichol',\n",
              " 'Philistim',\n",
              " 'Philistines',\n",
              " 'Phut',\n",
              " 'Phuvah',\n",
              " 'Pildash',\n",
              " 'Pinon',\n",
              " 'Pison',\n",
              " 'Potiphar',\n",
              " 'Potipherah',\n",
              " 'Put',\n",
              " 'Raamah',\n",
              " 'Rachel',\n",
              " 'Rameses',\n",
              " 'Rebek',\n",
              " 'Rebekah',\n",
              " 'Rehoboth',\n",
              " 'Remain',\n",
              " 'Rephaims',\n",
              " 'Resen',\n",
              " 'Return',\n",
              " 'Reu',\n",
              " 'Reub',\n",
              " 'Reuben',\n",
              " 'Reuel',\n",
              " 'Reumah',\n",
              " 'Riphath',\n",
              " 'Rosh',\n",
              " 'Sabtah',\n",
              " 'Sabtech',\n",
              " 'Said',\n",
              " 'Salah',\n",
              " 'Salem',\n",
              " 'Samlah',\n",
              " 'Sarah',\n",
              " 'Sarai',\n",
              " 'Saul',\n",
              " 'Save',\n",
              " 'Say',\n",
              " 'Se',\n",
              " 'Seba',\n",
              " 'See',\n",
              " 'Seeing',\n",
              " 'Seir',\n",
              " 'Sell',\n",
              " 'Send',\n",
              " 'Sephar',\n",
              " 'Serah',\n",
              " 'Sered',\n",
              " 'Serug',\n",
              " 'Set',\n",
              " 'Seth',\n",
              " 'Shalem',\n",
              " 'Shall',\n",
              " 'Shalt',\n",
              " 'Shammah',\n",
              " 'Shaul',\n",
              " 'Shaveh',\n",
              " 'She',\n",
              " 'Sheba',\n",
              " 'Shebah',\n",
              " 'Shechem',\n",
              " 'Shed',\n",
              " 'Shel',\n",
              " 'Shelah',\n",
              " 'Sheleph',\n",
              " 'Shem',\n",
              " 'Shemeber',\n",
              " 'Shepho',\n",
              " 'Shillem',\n",
              " 'Shiloh',\n",
              " 'Shimron',\n",
              " 'Shinab',\n",
              " 'Shinar',\n",
              " 'Shobal',\n",
              " 'Should',\n",
              " 'Shuah',\n",
              " 'Shuni',\n",
              " 'Shur',\n",
              " 'Sichem',\n",
              " 'Siddim',\n",
              " 'Sidon',\n",
              " 'Simeon',\n",
              " 'Sinite',\n",
              " 'Sitnah',\n",
              " 'Slay',\n",
              " 'So',\n",
              " 'Sod',\n",
              " 'Sodom',\n",
              " 'Sojourn',\n",
              " 'Some',\n",
              " 'Spake',\n",
              " 'Speak',\n",
              " 'Spirit',\n",
              " 'Stand',\n",
              " 'Succoth',\n",
              " 'Surely',\n",
              " 'Swear',\n",
              " 'Syrian',\n",
              " 'Take',\n",
              " 'Tamar',\n",
              " 'Tarshish',\n",
              " 'Tebah',\n",
              " 'Tell',\n",
              " 'Tema',\n",
              " 'Teman',\n",
              " 'Temani',\n",
              " 'Terah',\n",
              " 'Thahash',\n",
              " 'That',\n",
              " 'The',\n",
              " 'Then',\n",
              " 'There',\n",
              " 'Therefore',\n",
              " 'These',\n",
              " 'They',\n",
              " 'Thirty',\n",
              " 'This',\n",
              " 'Thorns',\n",
              " 'Thou',\n",
              " 'Thus',\n",
              " 'Thy',\n",
              " 'Tidal',\n",
              " 'Timna',\n",
              " 'Timnah',\n",
              " 'Timnath',\n",
              " 'Tiras',\n",
              " 'To',\n",
              " 'Togarmah',\n",
              " 'Tola',\n",
              " 'Tubal',\n",
              " 'Tubalcain',\n",
              " 'Twelve',\n",
              " 'Two',\n",
              " 'Unstable',\n",
              " 'Until',\n",
              " 'Unto',\n",
              " 'Up',\n",
              " 'Upon',\n",
              " 'Ur',\n",
              " 'Uz',\n",
              " 'Uzal',\n",
              " 'We',\n",
              " 'What',\n",
              " 'When',\n",
              " 'Whence',\n",
              " 'Where',\n",
              " 'Whereas',\n",
              " 'Wherefore',\n",
              " 'Which',\n",
              " 'While',\n",
              " 'Who',\n",
              " 'Whose',\n",
              " 'Whoso',\n",
              " 'Why',\n",
              " 'Wilt',\n",
              " 'With',\n",
              " 'Woman',\n",
              " 'Ye',\n",
              " 'Yea',\n",
              " 'Yet',\n",
              " 'Zaavan',\n",
              " 'Zaphnathpaaneah',\n",
              " 'Zar',\n",
              " 'Zarah',\n",
              " 'Zeboiim',\n",
              " 'Zeboim',\n",
              " 'Zebul',\n",
              " 'Zebulun',\n",
              " 'Zemarite',\n",
              " 'Zepho',\n",
              " 'Zerah',\n",
              " 'Zibeon',\n",
              " 'Zidon',\n",
              " 'Zillah',\n",
              " 'Zilpah',\n",
              " 'Zimran',\n",
              " 'Ziphion',\n",
              " 'Zo',\n",
              " 'Zoar',\n",
              " 'Zohar',\n",
              " 'Zuzims',\n",
              " 'a',\n",
              " 'abated',\n",
              " 'abide',\n",
              " 'able',\n",
              " 'abode',\n",
              " 'abomination',\n",
              " 'about',\n",
              " 'above',\n",
              " 'abroad',\n",
              " 'absent',\n",
              " 'abundantly',\n",
              " 'accept',\n",
              " 'accepted',\n",
              " 'according',\n",
              " 'acknowledged',\n",
              " 'activity',\n",
              " 'add',\n",
              " 'adder',\n",
              " 'afar',\n",
              " 'afflict',\n",
              " 'affliction',\n",
              " 'afraid',\n",
              " 'after',\n",
              " 'afterward',\n",
              " 'afterwards',\n",
              " 'aga',\n",
              " 'again',\n",
              " 'against',\n",
              " 'age',\n",
              " 'aileth',\n",
              " 'air',\n",
              " 'al',\n",
              " 'alive',\n",
              " 'all',\n",
              " 'almon',\n",
              " 'alo',\n",
              " 'alone',\n",
              " 'aloud',\n",
              " 'also',\n",
              " 'altar',\n",
              " 'altogether',\n",
              " 'always',\n",
              " 'am',\n",
              " 'among',\n",
              " 'amongst',\n",
              " 'an',\n",
              " 'and',\n",
              " 'angel',\n",
              " 'angels',\n",
              " 'anger',\n",
              " 'angry',\n",
              " 'anguish',\n",
              " 'anointedst',\n",
              " 'anoth',\n",
              " 'another',\n",
              " 'answer',\n",
              " 'answered',\n",
              " 'any',\n",
              " 'anything',\n",
              " 'appe',\n",
              " 'appear',\n",
              " 'appeared',\n",
              " 'appease',\n",
              " 'appoint',\n",
              " 'appointed',\n",
              " 'aprons',\n",
              " 'archer',\n",
              " 'archers',\n",
              " 'are',\n",
              " 'arise',\n",
              " 'ark',\n",
              " 'armed',\n",
              " 'arms',\n",
              " 'army',\n",
              " 'arose',\n",
              " 'arrayed',\n",
              " 'art',\n",
              " 'artificer',\n",
              " 'as',\n",
              " 'ascending',\n",
              " 'ash',\n",
              " 'ashamed',\n",
              " 'ask',\n",
              " 'asked',\n",
              " 'asketh',\n",
              " 'ass',\n",
              " 'assembly',\n",
              " 'asses',\n",
              " 'assigned',\n",
              " 'asswaged',\n",
              " 'at',\n",
              " 'attained',\n",
              " 'audience',\n",
              " 'avenged',\n",
              " 'aw',\n",
              " 'awaked',\n",
              " 'away',\n",
              " 'awoke',\n",
              " 'back',\n",
              " 'backward',\n",
              " 'bad',\n",
              " 'bade',\n",
              " 'badest',\n",
              " 'badne',\n",
              " 'bak',\n",
              " 'bake',\n",
              " 'bakemeats',\n",
              " 'baker',\n",
              " 'bakers',\n",
              " 'balm',\n",
              " 'bands',\n",
              " 'bank',\n",
              " 'bare',\n",
              " 'barr',\n",
              " 'barren',\n",
              " 'basket',\n",
              " 'baskets',\n",
              " 'battle',\n",
              " 'bdellium',\n",
              " 'be',\n",
              " 'bear',\n",
              " 'beari',\n",
              " 'bearing',\n",
              " 'beast',\n",
              " 'beasts',\n",
              " 'beautiful',\n",
              " 'became',\n",
              " 'because',\n",
              " 'become',\n",
              " 'bed',\n",
              " 'been',\n",
              " 'befall',\n",
              " 'befell',\n",
              " 'before',\n",
              " 'began',\n",
              " 'begat',\n",
              " 'beget',\n",
              " 'begettest',\n",
              " 'begin',\n",
              " 'beginning',\n",
              " 'begotten',\n",
              " 'beguiled',\n",
              " 'beheld',\n",
              " 'behind',\n",
              " 'behold',\n",
              " 'being',\n",
              " 'believed',\n",
              " 'belly',\n",
              " 'belong',\n",
              " 'beneath',\n",
              " 'bereaved',\n",
              " 'beside',\n",
              " 'besides',\n",
              " 'besought',\n",
              " 'best',\n",
              " 'betimes',\n",
              " 'better',\n",
              " 'between',\n",
              " 'betwixt',\n",
              " 'beyond',\n",
              " 'binding',\n",
              " 'bird',\n",
              " 'birds',\n",
              " 'birthday',\n",
              " 'birthright',\n",
              " 'biteth',\n",
              " 'bitter',\n",
              " 'blame',\n",
              " 'blameless',\n",
              " 'blasted',\n",
              " 'bless',\n",
              " 'blessed',\n",
              " 'blesseth',\n",
              " 'blessi',\n",
              " 'blessing',\n",
              " 'blessings',\n",
              " 'blindness',\n",
              " 'blood',\n",
              " 'blossoms',\n",
              " 'bodies',\n",
              " 'boldly',\n",
              " 'bondman',\n",
              " 'bondmen',\n",
              " 'bondwoman',\n",
              " 'bone',\n",
              " 'bones',\n",
              " 'book',\n",
              " 'booths',\n",
              " 'border',\n",
              " 'borders',\n",
              " 'born',\n",
              " 'bosom',\n",
              " 'both',\n",
              " 'bottle',\n",
              " 'bou',\n",
              " 'boug',\n",
              " 'bough',\n",
              " 'bought',\n",
              " 'bound',\n",
              " 'bow',\n",
              " 'bowed',\n",
              " 'bowels',\n",
              " 'bowing',\n",
              " 'boys',\n",
              " 'bracelets',\n",
              " 'branches',\n",
              " 'brass',\n",
              " 'bre',\n",
              " 'breach',\n",
              " 'bread',\n",
              " 'breadth',\n",
              " 'break',\n",
              " 'breaketh',\n",
              " 'breaking',\n",
              " 'breasts',\n",
              " 'breath',\n",
              " 'breathed',\n",
              " 'breed',\n",
              " 'brethren',\n",
              " 'brick',\n",
              " 'brimstone',\n",
              " 'bring',\n",
              " 'brink',\n",
              " 'broken',\n",
              " 'brook',\n",
              " 'broth',\n",
              " 'brother',\n",
              " 'brought',\n",
              " 'brown',\n",
              " 'bruise',\n",
              " 'budded',\n",
              " 'build',\n",
              " 'builded',\n",
              " 'built',\n",
              " 'bulls',\n",
              " 'bundle',\n",
              " 'bundles',\n",
              " 'burdens',\n",
              " 'buried',\n",
              " 'burn',\n",
              " 'burning',\n",
              " 'burnt',\n",
              " 'bury',\n",
              " 'buryingplace',\n",
              " 'business',\n",
              " 'but',\n",
              " 'butler',\n",
              " 'butlers',\n",
              " 'butlership',\n",
              " 'butter',\n",
              " 'buy',\n",
              " 'by',\n",
              " 'cakes',\n",
              " 'calf',\n",
              " 'call',\n",
              " 'called',\n",
              " 'came',\n",
              " 'camel',\n",
              " 'camels',\n",
              " 'camest',\n",
              " 'can',\n",
              " 'cannot',\n",
              " 'canst',\n",
              " 'captain',\n",
              " 'captive',\n",
              " 'captives',\n",
              " 'carcases',\n",
              " 'carried',\n",
              " 'carry',\n",
              " 'cast',\n",
              " 'castles',\n",
              " 'catt',\n",
              " 'cattle',\n",
              " 'caught',\n",
              " 'cause',\n",
              " 'caused',\n",
              " 'cave',\n",
              " 'cease',\n",
              " 'ceased',\n",
              " 'certain',\n",
              " 'certainly',\n",
              " 'chain',\n",
              " 'chamber',\n",
              " 'change',\n",
              " 'changed',\n",
              " 'changes',\n",
              " 'charge',\n",
              " 'charged',\n",
              " 'chariot',\n",
              " 'chariots',\n",
              " 'chesnut',\n",
              " 'chi',\n",
              " 'chief',\n",
              " 'child',\n",
              " 'childless',\n",
              " 'childr',\n",
              " 'children',\n",
              " 'chode',\n",
              " 'choice',\n",
              " 'chose',\n",
              " 'circumcis',\n",
              " 'circumcise',\n",
              " 'circumcised',\n",
              " 'citi',\n",
              " 'cities',\n",
              " 'city',\n",
              " 'clave',\n",
              " 'clean',\n",
              " 'clear',\n",
              " 'cleave',\n",
              " 'clo',\n",
              " 'closed',\n",
              " 'clothed',\n",
              " 'clothes',\n",
              " 'cloud',\n",
              " 'clusters',\n",
              " 'co',\n",
              " 'coat',\n",
              " 'coats',\n",
              " 'coffin',\n",
              " 'cold',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# to obtain the vocabulary of a given corpora (the unique words and punctuations)\n",
        "sorted(set(text3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9505b643",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2789\n",
            "44764\n",
            "6.230453042623537\n"
          ]
        }
      ],
      "source": [
        "print(len(set(text3)))\n",
        "print(len(text3))\n",
        "print(len(set(text3)) / len(text3) * 100)\n",
        "# what do you reveal comparing then number of tokens with the vocabulary number?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "306125de",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "484"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# to compute the number of occurances of a specific word\n",
        "text3.count(\"I\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d9f722",
      "metadata": {},
      "source": [
        "# Let's think about Text\n",
        "\n",
        "A text is a sequence of words and character (tokens) separated by white spaces, new lines, ...\n",
        "We can simply represent any corpora as a sequence of tokens so in python it is simply a list. This is how nltk represents text corporas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dc6290c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "sent1 = ['Call', 'me', 'Ishmael', '.']\n",
        "\n",
        "# to see the total number of tokens\n",
        "print(len(sent1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae813738",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'family',\n",
              " 'of',\n",
              " 'Dashwood',\n",
              " 'had',\n",
              " 'long',\n",
              " 'been',\n",
              " 'settled',\n",
              " 'in',\n",
              " 'Sussex',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sent2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2bccf8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['In',\n",
              " 'the',\n",
              " 'beginning',\n",
              " 'God',\n",
              " 'created',\n",
              " 'the',\n",
              " 'heaven',\n",
              " 'and',\n",
              " 'the',\n",
              " 'earth',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sent3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cd4011f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'family',\n",
              " 'of',\n",
              " 'Dashwood',\n",
              " 'had',\n",
              " 'long',\n",
              " 'been',\n",
              " 'settled',\n",
              " 'in',\n",
              " 'Sussex',\n",
              " '.',\n",
              " 'In',\n",
              " 'the',\n",
              " 'beginning',\n",
              " 'God',\n",
              " 'created',\n",
              " 'the',\n",
              " 'heaven',\n",
              " 'and',\n",
              " 'the',\n",
              " 'earth',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# to concatenate two sentences (lists)\n",
        "sent2 + sent3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88da8227",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Call', 'me', 'Ishmael', '.', 'Some']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# to add new token to a sentence\n",
        "sent1.append('Some')\n",
        "sent1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98fd6bc3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'awaken'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# to index a sentence (list) by index\n",
        "text4[173]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87443353",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "173"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# to get the first index of a specific word\n",
        "text4.index('awaken')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cced3ad",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['U86',\n",
              " 'thats',\n",
              " 'why',\n",
              " 'something',\n",
              " 'like',\n",
              " 'gamefly',\n",
              " 'is',\n",
              " 'so',\n",
              " 'good',\n",
              " 'because',\n",
              " 'you',\n",
              " 'can',\n",
              " 'actually',\n",
              " 'play',\n",
              " 'a',\n",
              " 'full',\n",
              " 'game',\n",
              " 'without',\n",
              " 'buying',\n",
              " 'it']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# You can use list slicing to get a part of the text\n",
        "text5[16715:16735]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7628ec6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'nltk.probability.FreqDist'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(',', 18713),\n",
              " ('the', 13721),\n",
              " ('.', 6862),\n",
              " ('of', 6536),\n",
              " ('and', 6024),\n",
              " ('a', 4569),\n",
              " ('to', 4542),\n",
              " (';', 4072),\n",
              " ('in', 3916),\n",
              " ('that', 2982)]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# To calculate the word count of a corpora\n",
        "fdist1 = FreqDist(text1)\n",
        "print(type(fdist1))\n",
        "fdist1.most_common(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f2498db",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "906"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fdist1['whale']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd624fc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['irresistibleness',\n",
              " 'undiscriminating',\n",
              " 'responsibilities',\n",
              " 'simultaneousness',\n",
              " 'uncomfortableness',\n",
              " 'cannibalistically',\n",
              " 'preternaturalness',\n",
              " 'indispensableness',\n",
              " 'apprehensiveness',\n",
              " 'circumnavigation',\n",
              " 'uninterpenetratingly',\n",
              " 'physiognomically',\n",
              " 'comprehensiveness',\n",
              " 'circumnavigating',\n",
              " 'subterraneousness',\n",
              " 'indiscriminately',\n",
              " 'circumnavigations',\n",
              " 'supernaturalness',\n",
              " 'Physiognomically',\n",
              " 'hermaphroditical',\n",
              " 'CIRCUMNAVIGATION',\n",
              " 'uncompromisedness',\n",
              " 'characteristically',\n",
              " 'superstitiousness']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# To filter words based on the word length\n",
        "# let's get the words having more than 15 character\n",
        "long_words = [w for w in set(text1) if len(w) > 15]\n",
        "long_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ba419a0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.', 'i', 'you', 'hi', 'I', ',', '?', 'JOIN', 'PART', 'lol', 'a', 'to', 'the']"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# what about filtering based on the word frequency in the corpora?\n",
        "fdist5 = FreqDist(text5)\n",
        "common_words = [w for w in set(text5) if fdist5[w] > 500]\n",
        "common_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a465077",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "# python built-in string comaprison operators\n",
        "\n",
        "# checks if string starts with sub-string\n",
        "print(\"omar\".startswith('o'))\n",
        "# checks if string ends with sub-string\n",
        "print(\"omar\".endswith('r'))\n",
        "# checks if string is sub-string of another\n",
        "print(\"ma\" in \"omar\")\n",
        "# checks if all characters in the string are lowercase\n",
        "print(\"omar\".islower())\n",
        "# checks if all characters in the string are uppercase\n",
        "print(\"OMAR\".isupper())\n",
        "# checks if all the characters in a string are alphabetic characters (a-z, A-Z) only\n",
        "print(\"omar\".isalpha())\n",
        "# checks if all the characters are alphanumeric (a-z, A-Z, 0-9) only\n",
        "print(\"omar1\".isalnum())\n",
        "# checks if all the characters are numeric (0-9) only\n",
        "print(\"123\".isdigit())\n",
        "# checks if the string is title-cased. (all words in a string begin with uppercase letters and the remaining characters are lowercase letters)\n",
        "print(\"Introduction To Python\".istitle())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "d91ff6b3",
        "977c721e",
        "c0b1c093",
        "cb02733b",
        "7d2a6132",
        "b3a7446d"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
